{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikethai/server-tools/blob/master/AudioToText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5hvo8QWN-a9"
      },
      "source": [
        "# üó£Ô∏è [**AudioToText**](https://github.com/Carleslc/AudioToText)\n",
        "\n",
        "[![Donate](https://www.ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/carleslc)\n",
        "\n",
        "### üõ† [Whisper by OpenAI](https://github.com/openai/whisper)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_lylR1xWMxk"
      },
      "source": [
        "## [Step 1] ‚öôÔ∏è Install the required libraries\n",
        "\n",
        "Click ‚ñ∂Ô∏è button below to install the dependencies for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SJl7HJOeo0-P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "392a846e-0955-424b-8e75-5788ca6f8115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "Requirement already satisfied: pip in /root/.local/lib/python3.11/site-packages (25.2)\n",
            "Collecting git+https://github.com/openai/whisper.git@v20231117\n",
            "  Cloning https://github.com/openai/whisper.git (to revision v20231117) to /tmp/pip-req-build-gvng_w_1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-gvng_w_1\n",
            "  Running command git checkout -q e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Resolved https://github.com/openai/whisper.git to commit e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai==1.9.0 in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Collecting numpy<2\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.16.1)\n",
            "Requirement already satisfied: deepl in /usr/local/lib/python3.11/dist-packages (1.22.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.11/dist-packages (5.17.0)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: tensorflow-probability==0.23.0 in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
            "Requirement already satisfied: typing-extensions==4.9.0 in /usr/local/lib/python3.11/dist-packages (4.9.0)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20231117) (0.60.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20231117) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20231117) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20231117) (0.11.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (1.17.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (3.1.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (0.1.9)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.5.82)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.9.0) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.9.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.9.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.9.0) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.9.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.9.0) (2.23.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from deepl) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->deepl) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->deepl) (2.5.0)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere) (1.12.0)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.4)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.4.20250809)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.1.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability==0.23.0) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability==0.23.0) (1.17.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20231117) (2024.11.6)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "raft-dask-cu12 25.6.0 requires nvidia-nccl-cu12>=2.19, but you have nvidia-nccl-cu12 2.18.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "b6b774f22efa4356b71aa76d38b76987"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "import subprocess\n",
        "\n",
        "from sys import platform as sys_platform\n",
        "\n",
        "status, ffmpeg_version = subprocess.getstatusoutput(\"ffmpeg -version\")\n",
        "\n",
        "if status != 0:\n",
        "  from platform import platform\n",
        "\n",
        "  if sys_platform == 'linux' and 'ubuntu' in platform().lower():\n",
        "    !apt install ffmpeg\n",
        "  else:\n",
        "    print(\"Install ffmpeg: https://ffmpeg.org/download.html\")\n",
        "else:\n",
        "  print(ffmpeg_version.split('\\n')[0])\n",
        "\n",
        "  NO_ROOT_WARNING = '|& grep -v \\\"WARNING: Running pip as the \\'root\\' user\"' # running in Colab\n",
        "\n",
        "  !pip install --no-warn-script-location --user --upgrade pip {NO_ROOT_WARNING}\n",
        "  !pip install --root-user-action=ignore git+https://github.com/openai/whisper.git@v20231117 openai==1.9.0 \"numpy<2\" scipy deepl pydub cohere ffmpeg-python torch==2.1.0 tensorflow-probability==0.23.0 typing-extensions==4.9.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A5bTMB8XmtI"
      },
      "source": [
        "## [Step 2] üìÅ Upload your audio files to the Files folder\n",
        "\n",
        "‚¨ÖÔ∏è Files folder in Google Colab is on the left menu\n",
        "\n",
        "Almost any audio or video file format is [supported](https://gist.github.com/Carleslc/1d6b922c8bf4a7e9627a6970d178b3a6)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS8OFGobrfJx"
      },
      "source": [
        "## [Step 2.5] üéô Record your own audio ‚è∫\n",
        "\n",
        "This is an **optional** step to record your microphone, useful if you do not have an audio file to upload and want to create one.\n",
        "\n",
        "Run this cell to start recording your microphone.\n",
        "A button will appear to stop the recording when you're done.\n",
        "\n",
        "The recording will be saved as `recording.wav` which you can use in the next step `audio_file`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BwkH_QCu60qd"
      },
      "outputs": [],
      "source": [
        "# This cell code is a slightly modified version of DotCSV code in the following Colab along with other references:\n",
        "# https://colab.research.google.com/drive/1CvvYPAFemIZdSOt9fhN541esSlZR7Ic6?usp=sharing\n",
        "\n",
        "try:\n",
        "  import io\n",
        "  import ffmpeg\n",
        "  import numpy as np\n",
        "\n",
        "  # Only available in Google Colab\n",
        "  from google.colab.output import eval_js\n",
        "\n",
        "  from IPython.display import HTML, Audio\n",
        "  from scipy.io.wavfile import write, read as wav_read\n",
        "  from base64 import b64decode\n",
        "  from os.path import isfile\n",
        "\n",
        "  AUDIO_HTML = \"\"\"\n",
        "  <script>\n",
        "  var my_div = document.createElement(\"DIV\");\n",
        "  var my_p = document.createElement(\"P\");\n",
        "  var my_btn = document.createElement(\"BUTTON\");\n",
        "  var t = document.createTextNode(\"Starting recording...\");\n",
        "\n",
        "  my_btn.appendChild(t);\n",
        "  my_div.appendChild(my_btn);\n",
        "  document.body.appendChild(my_div);\n",
        "\n",
        "  var base64data = 0;\n",
        "  var reader;\n",
        "  var recorder, gumStream;\n",
        "  var recordButton = my_btn;\n",
        "\n",
        "  var handleSuccess = function(stream) {\n",
        "    gumStream = stream;\n",
        "    var options = {\n",
        "      bitsPerSecond: 16000,\n",
        "      mimeType : 'audio/webm;codecs=opus' //codecs=pcm\n",
        "    };\n",
        "    recorder = new MediaRecorder(stream, options);\n",
        "    //recorder = new MediaRecorder(stream);\n",
        "\n",
        "    recorder.ondataavailable = function(e) {\n",
        "      var url = URL.createObjectURL(e.data);\n",
        "      var preview = document.createElement('audio');\n",
        "      preview.controls = true;\n",
        "      preview.src = url;\n",
        "      document.body.appendChild(preview);\n",
        "\n",
        "      reader = new FileReader();\n",
        "      reader.readAsDataURL(e.data);\n",
        "      reader.onloadend = function() {\n",
        "        base64data = reader.result;\n",
        "        //console.log(\"reader.onloadend: \" + base64data);\n",
        "      }\n",
        "    };\n",
        "    recorder.start();\n",
        "    recordButton.innerText = \"üî¥ Recording... press to STOP\";\n",
        "  };\n",
        "\n",
        "  navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "  function toggleRecording() {\n",
        "    if (recorder && recorder.state == \"recording\") {\n",
        "        recorder.stop();\n",
        "        gumStream.getAudioTracks()[0].stop();\n",
        "        recordButton.innerText = \"Saving the recording... please wait!\";\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // https://stackoverflow.com/a/951057\n",
        "  function sleep(ms) {\n",
        "    return new Promise(resolve => setTimeout(resolve, ms));\n",
        "  }\n",
        "\n",
        "  var data = new Promise(resolve => {\n",
        "    recordButton.onclick = () => {\n",
        "      toggleRecording();\n",
        "\n",
        "      sleep(2000).then(() => {\n",
        "        // wait 2000ms for the data to be available...\n",
        "        //console.log(\"resolve data: \" + base64data);\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  });\n",
        "\n",
        "  function doneRecording(recording_file) {\n",
        "    my_div.removeChild(recordButton);\n",
        "    my_p.innerText = recording_file;\n",
        "    my_div.appendChild(my_p);\n",
        "  }\n",
        "\n",
        "  </script>\n",
        "  \"\"\"\n",
        "\n",
        "  def get_audio():\n",
        "    display(HTML(AUDIO_HTML))\n",
        "    data = eval_js(\"data\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    process = (ffmpeg\n",
        "      .input('pipe:0')\n",
        "      .output('pipe:1', format='wav')\n",
        "      .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "    )\n",
        "    output, err = process.communicate(input=binary)\n",
        "\n",
        "    riff_chunk_size = len(output) - 8\n",
        "    # Break up the chunk size into four bytes, held in b.\n",
        "    q = riff_chunk_size\n",
        "    b = []\n",
        "    for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "    # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "    riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "    sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "    return audio, sr\n",
        "\n",
        "  recording_file = \"recording.wav\" #@param {type:\"string\"}\n",
        "\n",
        "  if isfile(recording_file):\n",
        "    print(f\"{recording_file} already exists, if you want to create another recording with the same name, delete it first\")\n",
        "  else:\n",
        "    # record microphone\n",
        "    audio, sr = get_audio()\n",
        "\n",
        "    # write recording\n",
        "    write(recording_file, sr, audio)\n",
        "\n",
        "    eval_js(f'doneRecording(\"{recording_file}\")')\n",
        "except ImportError:\n",
        "  print(\"Recording only available in Google Colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9_I0W3tqTjr"
      },
      "source": [
        "## [Step 3] üëÇ Transcribe or Translate\n",
        "\n",
        "3.1. Choose a `task`:\n",
        "  - `Transcribe` speech to text in the same language of the source audio file.\n",
        "  - `Translate to English` speech to text in English.\n",
        "  \n",
        "Translation to other languages is not supported with _Whisper_ by default.\n",
        "You may try to choose the _Transcribe_ task and set your desired `language`, but translation is not guaranteed. However, you can use **_DeepL_** later in the Step 5 to translate the transcription to another language.\n",
        "\n",
        "3.2. Edit the `audio_file` to match your uploaded file name to transcribe.\n",
        "\n",
        "- If you want to transcribe multiple files with the same parameters you must separate their file names with commas `,`\n",
        "\n",
        "3.3. Run this cell and wait for the transcription to complete.\n",
        "\n",
        "  You can try other parameters if the result with default parameters does not suit your needs.\n",
        "\n",
        "  [Available models and languages](https://github.com/openai/whisper#available-models-and-languages)\n",
        "\n",
        "  Setting the `language` to the language of source audio file may provide better results than Auto-Detect.\n",
        "\n",
        "  You can add an optional initial `prompt` to provide context about the audio or encourage a specific writing style, see the [prompting guide](https://platform.openai.com/docs/guides/speech-to-text/prompting).\n",
        "\n",
        "  If the execution takes too long to complete you can choose a smaller model in `use_model`, with an accuracy tradeoff, or use the OpenAI API.\n",
        "\n",
        "  By default the open-source models are used, but you can also use the OpenAI API if the `api_key` parameter is set with your [OpenAI API Key](https://platform.openai.com/account/api-keys), which can improve the inference speed substantially, but it has an associated cost, see [API pricing](https://openai.com/pricing#audio-models).\n",
        "\n",
        "  When using API some options are fixed: **use_model** is ignored (uses _large-v2_) and **coherence_preference** is ignored (uses _More coherence_).\n",
        "  \n",
        "  More parameters are available in the code `options` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "opNkn_Lgpat4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47720a1-f426-4af4-e3b9-ee8aee522cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU\n",
            "GPU 0: Tesla T4 (UUID: GPU-2838dafe-127f-f1b5-e7a7-f1755681906c)\n",
            "\n",
            "Language: Chinese\n",
            "\n",
            "Loading medium model... /root/.cache/whisper/medium.pt\n",
            "Model medium is multilingual and has 762,321,920 parameters.\n",
            "\n",
            "-- TRANSCRIPTION --\n",
            "\n",
            "Processing: /content/12-10Ë´áËá™Áµê.m4a\n",
            "\n",
            "[00:00.000 --> 00:02.000] Â§ßÂÆ∂Êôö‰∏äÂ•Ω\n",
            "[00:02.000 --> 00:04.000] ÈÇ£\n",
            "[00:04.000 --> 00:06.000] ÈÄôÂÄã‰ªäÂ§©\n",
            "[00:06.000 --> 00:08.000] ÊàëÂÄëË¶Å‰æÜË¨õ‰∏ÄÂÄãÂè´ÂÅö\n",
            "[00:08.000 --> 00:10.000] Âè∞Èºì\n",
            "[00:10.000 --> 00:12.000] Áç®ÊúâÁöÑÂêß\n",
            "[00:12.000 --> 00:14.000] Êàë‰∏çÁü•ÈÅìÂÖ∂‰ªñÂêÑÂúãÊúÉ‰∏çÊúÉÊúâ\n",
            "[00:14.000 --> 00:16.000] ‰ΩÜÊòØÊàëË¶∫ÂæóÊàëÂÄëÂè∞ÈºìÈÄôÂÄãÊù±Ë•ø\n",
            "[00:16.000 --> 00:18.000] ÂØ¶Âú®ÊòØË†ªÂèØÊÑõÁöÑ\n",
            "[00:18.000 --> 00:20.000] ÈÇ£Â∞±ÊòØ‰ªÄÈ∫º,Â∞±ÊòØÂ≠óÁØÄ\n",
            "[00:20.000 --> 00:22.000] ‰ªÄÈ∫ºÂè´Â≠óÁØÄ\n",
            "[00:22.000 --> 00:24.000] Â∞±ÊòØÂ≠óÁØÄË≤°Â†±\n",
            "[00:24.000 --> 00:26.000] Â≠óÁØÄÂ†±Ë°®\n",
            "[00:26.000 --> 00:28.000] ÈÇ£Â≠óÁØÄÂ†±Ë°®ÊúÉÊúâ‰∏ÄÂÄãÁâπËâ≤\n",
            "[00:28.000 --> 00:30.000] ÂëÉ\n",
            "[00:30.000 --> 00:32.000] ‰ªñÂÄëÈÄôÂÄãÈÄöÂ∏∏ÈÉΩÊòØ\n",
            "[00:32.000 --> 00:34.000] ÊØîÂ¶ÇË™™‰Ω†\n",
            "[00:34.000 --> 00:36.000] Ê≥¢ÂãïÂæàÂ§ß,ÊØîÂ¶ÇË™™‰Ω†\n",
            "[00:36.000 --> 00:38.000] Êº≤ËÄóÈáëË∑üÂÅúÊùø\n",
            "[00:38.000 --> 00:40.000] ÈÇ£‰ªäÂ§©ÊòØ11Êúà25\n",
            "[00:40.000 --> 00:42.000] ÂÉè\n",
            "[00:42.000 --> 00:44.000] ÊàëÂÄëÂâç‰∏ÄÂÄãÈü≥Ê™îË¨õÂà∞ÁöÑ\n",
            "[00:44.000 --> 00:46.000] ÈÄô‰∏ÄÂÄãAES\n",
            "[00:46.000 --> 00:48.000] ÁõÆÂâçÈÇÑÊòØ\n",
            "[00:48.000 --> 00:50.000] Â±¨Êñº‰∏ÄÂÄã‰ªÄÈ∫º\n",
            "[00:50.000 --> 00:52.000] ÈÄôÂÄãËôïÁΩÆ\n",
            "[00:52.000 --> 00:54.000] ËôïÁΩÆÁöÑÁãÄÊÖã\n",
            "[00:54.000 --> 00:56.000] ÈÇ£ÁÇ∫‰ªÄÈ∫ºÊúÉËôïÁΩÆ\n",
            "[00:56.000 --> 00:58.000] Â∞±ÊòØÊº≤ÂπÖÊ≥¢ÂãïÂ§™Â§ß\n",
            "[00:58.000 --> 01:00.000] Êº≤ÂπÖÊ≥¢ÂãïÂ§™Â§ß\n",
            "[01:00.000 --> 01:02.000] ÈÇ£ÈÄôÂÄãÂâçÈù¢Èü≥Ë∑üÈü≥Ê™î\n",
            "[01:02.000 --> 01:04.000] ‰πüÊúâÊèêÂà∞ÈÄôÂÄã3211ÁöÑÈ†ÜÂ§ß\n",
            "[01:04.000 --> 01:06.000] ÁõÆÂâçÂà∞11Êúà25Ëôü\n",
            "[01:06.000 --> 01:08.000] ‰πüÈÇÑÂú®‰ªÄÈ∫º‰∏ÄÂÄãËôïÁΩÆÁöÑÁãÄÊÖã\n",
            "[01:08.000 --> 01:10.000] ÈÇ£ËôïÁΩÆÁöÑÁãÄÊÖã\n",
            "[01:10.000 --> 01:12.000] ÂêÑ‰ΩçÂ∞±ÊúÉÁôºÁèæ‰ªñÈáèÂ∞±ÊúÉÁ∏ÆÂæó\n",
            "[01:12.000 --> 01:14.000] ÂæàË™áÂºµ\n",
            "[01:14.000 --> 01:16.000] ÈÇ£ÈáèÁ∏ÆÂæóÂæàË™áÂºµÊòØÁÇ∫‰ªÄÈ∫º\n",
            "[01:16.000 --> 01:18.000] ÊòØÂõ†ÁÇ∫Áï∂‰ªñËôïÁΩÆÁöÑÊôÇÂÄô\n",
            "[01:18.000 --> 01:20.000] ‰ªñË≤∑ÁöÑ‰∫∫\n",
            "[01:20.000 --> 01:22.000] Â¶ÇÊûúÂºµÊï∏ÊØîËºÉÂ§öÁöÑË©±\n",
            "[01:22.000 --> 01:24.000] ‰ªñÊòØÈúÄË¶ÅÂåØÈå¢\n",
            "[01:24.000 --> 01:26.000] Á¨¨‰∫åÊ¨°ËôïÁΩÆÁöÑË©±\n",
            "[01:26.000 --> 01:28.000] ‰ªñÂü∫Êú¨‰∏äÂ∞±Â∑≤Á∂ì\n",
            "[01:28.000 --> 01:30.000] ‰∏ÄÂÆöË¶ÅÂåØÈå¢‰∫Ü\n",
            "[01:30.000 --> 01:32.000] ‰Ω†Âπ≥Â∏∏Ë≤∑ËÇ°Á•®‰∏çÁî®ÂåØÈå¢\n",
            "[01:32.000 --> 01:34.000] ÊêûÂà∞ÁèæÂú®\n",
            "[01:34.000 --> 01:36.000] Ë¶ÅÂÖàÂåØÁµ¶Âà∏ÂïÜ\n",
            "[01:36.000 --> 01:38.000] ‰Ω†Â∞±ÊúÉË¶∫ÂæóÈ∫ªÁÖ©\n",
            "[01:38.000 --> 01:40.000] ÈÇ£‰Ω†Ë¶∫ÂæóÈ∫ªÁÖ©ÁöÑÊÉÖÊ≥Å‰∏ã\n",
            "[01:40.000 --> 01:42.000] Ë≤∑ÁöÑ‰∫∫Ë≥áÁî¢Â∞±Â∞ë\n",
            "[01:42.000 --> 01:44.000] Ë≤∑ÁöÑ‰∫∫Â∞ëÁöÑÊôÇÂÄô\n",
            "[01:44.000 --> 01:46.000] ÂÉπÊ†ºË¶Å\n",
            "[01:46.000 --> 01:48.000] ÂÜçÂæÄ‰∏äÊº≤\n",
            "[01:48.000 --> 01:50.000] ÊàëÂÄëÈÉΩÁü•ÈÅì\n",
            "[01:50.000 --> 01:52.000] ‰∏ÄÂÄãÂ•ΩÁöÑËµ∞Âã¢\n",
            "[01:52.000 --> 01:54.000] ÂÉπ\n",
            "[01:54.000 --> 01:56.000] Èáè\n",
            "[01:56.000 --> 01:58.000] ÂÉπ‰πüÊº≤\n",
            "[01:58.000 --> 02:00.000] Èáè‰πüÊº≤\n",
            "[02:00.000 --> 02:02.000] ÂïèÈ°åÊòØÁèæÂú®\n",
            "[02:02.000 --> 02:04.000] ‰ªñÊää‰Ω†Èéñ‰Ωè‰∫Ü\n",
            "[02:04.000 --> 02:06.000] ËÆäÁõ∏ÁöÑ\n",
            "[02:06.000 --> 02:08.000] Ë≤∑Áõ§‰ªñÈéñ‰Ωè‰∫Ü\n",
            "[02:08.000 --> 02:10.000] ‰Ω†Â∞±‰∏çÂÆπÊòì‰∏ÄÁõ¥Êº≤‰∏äÂéª\n",
            "[02:10.000 --> 02:12.000] ÊâÄ‰ª•‰ªñÂ∞±ÊòØ\n",
            "[02:12.000 --> 02:14.000] Âú®ÈÅèÊ≠¢‰Ω†ÈÇ£ÂÄãÁÜ±Â∫¶\n",
            "[02:14.000 --> 02:16.000] ‰∏çËÆì‰Ω†‰∏ÄÁõ¥Êªæ‰∏äÂéª\n",
            "[02:16.000 --> 02:18.000] ‰∏ÄÁõ¥ÁÇí‰Ωú\n",
            "[02:18.000 --> 02:20.000] ÈÇ£ÈÄôÂÄãÊòØÊúâÂ•ΩÊúâÂ£û\n",
            "[02:20.000 --> 02:22.000] ÊàëË™çÁÇ∫Â•ΩÁöÑÊôÇÂÄô\n",
            "[02:22.000 --> 02:24.000] ÊòØÂ∞çÊñºË™™\n",
            "[02:24.000 --> 02:26.000] ‰∏Ä‰∫õËÖ∞È™®\n",
            "[02:26.000 --> 02:28.000] ‰∏çË¶ÅÈÄôÈ∫ºÊÖòÁÉà\n",
            "[02:28.000 --> 02:30.000] Âõ†ÁÇ∫ËÖ∞È™®\n",
            "[02:30.000 --> 02:32.000] ÂæàÁåõÁöÑ‰∏äÂéª\n",
            "[02:32.000 --> 02:34.000] ‰πüÊòØÂæàÊÖòÁöÑ‰∏ã‰æÜ\n",
            "[02:34.000 --> 02:36.000] ÈÄôÂÄã\n",
            "[02:36.000 --> 02:38.000] ‰πãÂâç\n",
            "[02:38.000 --> 02:40.000] Ë¨õ‰∫ÜÂæàÂ§öËÇ°Á•®\n",
            "[02:40.000 --> 02:42.000] ÊàëÂÄëÂú®Ë´áËÖ∞È™®ÈÇ£ÈÇäÈÉΩË¨õÈÅéÂæàÂ§öËÇ°Á•®\n",
            "[02:42.000 --> 02:44.000] ‰Ω†ÁèæÂú®ÂÜçÂéªÁúã\n",
            "[02:44.000 --> 02:46.000] ÈÇ£ÂÄãËÖ∞È™®Â§ßÊ¶ÇÈÉΩÊòØ\n",
            "[02:46.000 --> 02:48.000] ÂõûÂà∞ÂéüÈªû\n",
            "[02:48.000 --> 02:50.000] ‰ª•Ââç‰πüÂæàÂ§öËÖ∞È™®\n",
            "[02:50.000 --> 02:52.000] ÈÇ£ÂÄã\n",
            "[02:52.000 --> 02:54.000] Âè£ÁΩ©ÈÇ£ÂÄãÊôÇ‰ª£\n",
            "[02:54.000 --> 02:56.000] Â∫∑Á¥çÁÆ±\n",
            "[02:56.000 --> 02:58.000] ÊÅÜÂ§ß\n",
            "[02:58.000 --> 03:00.000] 20Â°äÁöÑÊôÇÂÄô\n",
            "[03:00.000 --> 03:02.000] Êº≤Âà∞200Â°ä\n",
            "[03:02.000 --> 03:04.000] ÁÇí‰Ωú‰∏ÄÂÄãÁñ´ÊÉÖ\n",
            "[03:04.000 --> 03:06.000] ÈÇ£\n",
            "[03:06.000 --> 03:08.000] ÈÇ£ÂãÅÂ§ßÁÆ±ÊÅÜÂ§ß\n",
            "[03:08.000 --> 03:10.000] ÊÅÜÂ§ßÂâ©28Â°ä\n",
            "[03:10.000 --> 03:12.000] 28Â°ä\n",
            "[03:12.000 --> 03:14.000] ÊâÄ‰ª•‰Ω†Â∞±Áü•ÈÅì\n",
            "[03:14.000 --> 03:16.000] ÁÇí‰ΩúÊù±Ë•øÁúüÁöÑÊòØ\n",
            "[03:16.000 --> 03:18.000] ‰∏çÈï∑‰πÖ\n",
            "[03:18.000 --> 03:20.000] ÈÇ£ÊàëÂÄëÂ∞±Ë¨õ\n",
            "[03:20.000 --> 03:22.000] ÈÄôÂÄã\n",
            "[03:22.000 --> 03:24.000] ËôïÁΩÆËÇ°\n",
            "[03:24.000 --> 03:26.000] Âà∞Â∫ïÊúâ‰ªÄÈ∫ºÂ•ΩÊúâ‰ªÄÈ∫ºÂ∑Æ\n",
            "[03:26.000 --> 03:28.000] ÂêÑ‰ΩçÂèØ‰ª•ÂéªÊÄùËÄÉ‰∏Ä‰∏ã\n",
            "[03:28.000 --> 03:30.000] ÊâÄË¨ÇÁöÑÂ•Ω\n",
            "[03:30.000 --> 03:32.000] Â∞±ÊòØÂÆÉÊúâ‰∏ÄÂÄãÂè´ÂÅö\n",
            "[03:32.000 --> 03:34.000] Ëá™Ëß£ÁöÑÈÉ®ÂàÜ\n",
            "[03:34.000 --> 03:36.000] ÈÄôÂÄãËá™Ëß£Âë¢\n",
            "[03:36.000 --> 03:38.000] Áï∂ÂÆÉÁöÑ\n",
            "[03:38.000 --> 03:40.000] Ê≥¢ÂãïÈùûÂ∏∏Â§ßÁöÑÊôÇÂÄô\n",
            "[03:40.000 --> 03:42.000] ÂÖ¨Âè∏ÊúÉÂè´‰Ω†Ëá™Â∑±ÂÖàÁµêÂ∏≥\n",
            "[03:42.000 --> 03:44.000] Â∞±‰Ω†ÈÄôÂÄãÊúà\n",
            "[03:44.000 --> 03:46.000] EPSÂ§öÂ∞ë‰Ω†Ë¶ÅË∑ü‰∫∫ÂÆ∂Ë¨õ\n",
            "[03:46.000 --> 03:48.000] ‰∏çÊòØÂÖ¨‰ΩàÁáüÊî∂\n",
            "[03:48.000 --> 03:50.000] ÁáüÊî∂ÊòØÊØèÂÄãÊúàÈÉΩË¶ÅË¨õ\n",
            "[03:50.000 --> 03:52.000] ‰ΩÜÊòØËá™Ëß£ÈÄôÂÄãEPSÂ∞±ÊòØ\n",
            "[03:52.000 --> 03:54.000] Êîø‰∫§ÊâÄ\n",
            "[03:54.000 --> 03:56.000] Âè´‰Ω†Ë¨õÁöÑÊôÇÂÄô‰Ω†Â∞±Ë¶ÅË¨õÂá∫‰æÜ\n",
            "[03:56.000 --> 03:58.000] ‰Ω†Â∞±Ë∂ïÂø´ÂéªÁÆó\n",
            "[03:58.000 --> 04:00.000] ÈÇ£\n",
            "[04:00.000 --> 04:02.000] ÈÄôÂÄãÊúâÂ•ΩÊúâÂ£û\n",
            "[04:02.000 --> 04:04.000] ÊØîÂ¶ÇË™™‰ªÄÈ∫º\n",
            "[04:04.000 --> 04:06.000] Â¶ÇÊûúÂÆÉÁöÑÈÄôÂÄãÂÖ¨Âè∏\n",
            "[04:06.000 --> 04:08.000] ÊòØÂõ†ÁÇ∫Âü∫Êú¨Èù¢Êº≤ÁöÑÊôÇÂÄô\n",
            "[04:08.000 --> 04:10.000] ÂÆÉÂ¶ÇÊûúÂÖ¨‰ΩàÂá∫‰æÜ\n",
            "[04:10.000 --> 04:12.000] ‰∏çÂ•ΩÁöÑÊôÇÂÄôÈÄôËÇ°ÂÉπÂèØËÉΩÊúÉ\n",
            "[04:12.000 --> 04:14.000] ÊúÉËΩâÊäï\n",
            "[04:14.000 --> 04:16.000] ÈÇ£ÂÉèÊàë‰πãÂâç‰∏çÊòØÊúâ\n",
            "[04:16.000 --> 04:18.000] Ë≤∑ÈÅéÈÇ£ÂÄãÈ≥≥Âá∞\n",
            "[04:18.000 --> 04:20.000] ÂêÑ‰ΩçÈÉΩÁü•ÈÅìÈÄôÂÄãÂ∑≤Á∂ìË¨õÂæàÂ§öÊ¨°\n",
            "[04:20.000 --> 04:22.000] ÁÇ∫‰ªÄÈ∫ºÂõ†ÁÇ∫ÁúãÂ•ΩÂÆÉÁöÑÈÄôÂÄã\n",
            "[04:22.000 --> 04:24.000] ÊóÖÈÅä\n",
            "[04:24.000 --> 04:26.000] Ë∑üÈ¢®ÊΩÆ\n",
            "[04:26.000 --> 04:28.000] ‰∏âÂØåË≤∑‰∫îÂØåË≤∑‰∫îÂØå\n",
            "[04:28.000 --> 04:30.000] Ë≤∑ÈÄôÂÄãÈ≥≥Âá∞\n",
            "[04:30.000 --> 04:32.000] ÊÉ≥Ë¶ÅË∑ü‰∏ÄÊ≥¢\n",
            "[04:32.000 --> 04:34.000] Â∑≤Á∂ìË≥∫‰∫Ü100Ëê¨Âñî\n",
            "[04:34.000 --> 04:36.000] ÁµêÊûúÊÄéÈ∫ºÊ®£\n",
            "[04:36.000 --> 04:38.000] ÂÆÉÂÖ¨‰Ωà‰∏ÄÂÄãË≤°Â†±\n",
            "[04:38.000 --> 04:40.000] ÈöîÂ§©ÊàëÊòØÁî®Ë∑åÂÅúÊùøÊääÂÆÉÁ†çÊéâ\n",
            "[04:40.000 --> 04:42.000] ‰ΩÜÊòØÊàëÊòØÂá∫ÁöÑÈùûÂ∏∏ÊºÇ‰∫Æ\n",
            "[04:42.000 --> 04:44.000] Âõ†ÁÇ∫‰ªÄÈ∫ºÂõ†ÁÇ∫ÈÇ£ÂÄãÊôÇÂÄô\n",
            "[04:44.000 --> 04:46.000] ‰πùÂçÅÂπæÂ°äÊàëË™™Âú®‰πùÂçÅ‰∏âÂ°ä\n",
            "[04:46.000 --> 04:48.000] ÊàëË≤∑ÂÖ≠ÂçÅÂπæÂ°ä\n",
            "[04:48.000 --> 04:50.000] ÂçÅÂ§©ËÄåÂ∑≤Â∞±Ë≥∫‰∏ÄÁôæ\n",
            "[04:50.000 --> 04:52.000] ÈÇ£‰πùÂçÅÂπæÂ°äÂÆÉ\n",
            "[04:52.000 --> 04:54.000] Âæå‰æÜ‰∏ÄÁõ¥ÊÆ∫ÊÆ∫ÊÆ∫ÊÆ∫\n",
            "[04:54.000 --> 04:56.000] Âà∞‰∏ÉÂÖ´ÂçÅ\n",
            "[04:56.000 --> 04:58.000] ÊâÄ‰ª•Â¶ÇÊûúÊàë\n",
            "[04:58.000 --> 05:00.000] Ê≤íÊúâÊÆ∫ÁöÑË©±ÊàëÂèØËÉΩÊúÄÂæå‰∏ÄÊ¨°ÊÆ∫Âà∞‰∏ÉÂÖ´ÂçÅ\n",
            "[05:00.000 --> 05:02.000] ÈÇ£ÁÇ∫‰ªÄÈ∫ºÈÇ£Â∞±ÊòØÂõ†ÁÇ∫ÂÆÉ\n",
            "[05:02.000 --> 05:04.000] ‰∏ÄÂÄãËá™Ëß£Âá∫‰æÜ\n",
            "[05:04.000 --> 05:06.000] Ëá™Ëß£\n",
            "[05:06.000 --> 05:08.000] ÊàëÊòØÂøò‰∫ÜÈÇ£ÂÄãÊôÇÂÄôÊòØÊ≠£ÈÇÑÊòØ\n",
            "[05:08.000 --> 05:10.000] ‰ΩÜÊòØ‰∏çÊòØÂæàÁêÜÊÉ≥\n",
            "[05:10.000 --> 05:12.000] ‰∏çÊòØÂæàÁêÜÊÉ≥\n",
            "[05:12.000 --> 05:14.000] ÊâÄ‰ª•ÊàëÂ∞±ÊääÂÆÉË≥£\n",
            "[05:14.000 --> 05:16.000] ÊâÄ‰ª•\n",
            "[05:16.000 --> 05:18.000] Â¶ÇÊûúÊàëÊòØÂõ†ÁÇ∫ÂÆÉÁöÑÂü∫Êú¨Èù¢\n",
            "[05:18.000 --> 05:20.000] Â•ΩÁöÑÊôÇÂÄôÈÄ≤ÂéªË≤∑ÁöÑÊôÇÂÄô\n",
            "[05:20.000 --> 05:22.000] ÂÆÉÁöÑÂ≠óÁØÄ‰∏çÂ•ΩÁöÑÊôÇÂÄô\n",
            "[05:22.000 --> 05:24.000] ÊàëÊúÉÂá∫ËÇ°Á•®\n",
            "[05:24.000 --> 05:26.000] ÊàëÁîöËá≥‰πü‰∏çÁî®Á≠âÂà∞‰ªÄÈ∫ºË≥£Âá∫‰∏âËó•Âäë\n",
            "[05:26.000 --> 05:28.000] Âõ†ÁÇ∫‰Ω†Ë≤∑\n",
            "[05:28.000 --> 05:30.000] Áõ°ÁöÑÁêÜÁî±Â∞±Ê∂àÂ§±Âï¶\n",
            "[05:30.000 --> 05:32.000] ‰Ω†Ë≤∑Áõ°ÁöÑÁêÜÁî±ÊòØÁúãÂ•Ω\n",
            "[05:32.000 --> 05:34.000] ÂÆÉÂü∫Êú¨Èù¢‰∏ÄÁõ¥\n",
            "[05:34.000 --> 05:36.000] ‰∏ÄÁõ¥ÊàêÈï∑‰Ω†‰∏çÂèØËÉΩÂéªË≤∑\n",
            "[05:36.000 --> 05:38.000] ÊàêÈï∑‰∏ÄÂÖ©Â≠£ÁÑ∂ÂæåÂæåÈù¢ÈÉΩ\n",
            "[05:38.000 --> 05:40.000] Ë°∞ÈÄÄÁöÑËÇ°Á•®ÈÄô‰∏çÂèØËÉΩ\n",
            "[05:40.000 --> 05:42.000] ‰Ω†‰∏ÄÂÆöÊòØË≤∑‰∏ÄÁõ¥ÊàêÈï∑ÁöÑËÇ°Á•®\n",
            "[05:42.000 --> 05:44.000] ÈÇ£ÊàêÈï∑ÂÅúÊ≠¢ÊàñÊòØ\n",
            "[05:44.000 --> 05:46.000] ÊàêÈï∑Ë∂®Á∑©ÁöÑÊôÇÂÄôÂ∞±Ë¶ÅË≥£Êéâ\n",
            "[05:46.000 --> 05:48.000] Â∞çÂêßÂ∞±Ë¶ÅË≥£Êéâ\n",
            "[05:48.000 --> 05:50.000] ÊâÄ‰ª•‰Ω†Ë¶ÅÂéªÊÄùËÄÉË™™\n",
            "[05:50.000 --> 05:52.000] ÊàëÂÄëÈÄôÂÖ©ËÇ°Á•®Âà∞Â∫ïÊòØ\n",
            "[05:52.000 --> 05:54.000] ÁáüÈÅãÁãÄÊ≥Å\n",
            "[05:54.000 --> 05:56.000] ÊòØ‰∏çÊòØ‰∏ÄÁõ¥Âú®Â•ΩËΩâ\n",
            "[05:56.000 --> 05:58.000] ‰∏ÄÁõ¥Âú®Â¢ûÂä†\n",
            "[05:58.000 --> 06:00.000] ÈÇ£ÊàëÂ∏∏Â∏∏Ë¨õË™™ÂÖ∂ÂØ¶ÂÉèÊàë\n",
            "[06:00.000 --> 06:02.000] ÊàëÂÄëÈÄôÂõõÂπ¥ÁöÑ\n",
            "[06:02.000 --> 06:04.000] ‰∏ÄÂÄãÁ∏æÊïàÂ§ßÊ¶Ç\n",
            "[06:04.000 --> 06:06.000] ÊØèÂπ¥ÈÉΩÊòØ\n",
            "[06:06.000 --> 06:08.000] 100%Â∑¶Âè≥\n",
            "[06:08.000 --> 06:10.000] Âπ¥Âåñ‰øùÂÆàÁéá\n",
            "[06:10.000 --> 06:12.000] ÂêÑ‰ΩçÂèØ‰ª•Áúã\n",
            "[06:12.000 --> 06:14.000] 120ÊàëÂÄë‰πò‰ª•\n",
            "[06:14.000 --> 06:16.000] 100%\n",
            "[06:16.000 --> 06:18.000] Â∞±‰πò‰ª•2\n",
            "[06:18.000 --> 06:20.000] Á¨¨‰∫åÂπ¥Â∞±ËÆä240\n",
            "[06:20.000 --> 06:22.000] ÊàëÊòØ120ÈñãÂßãÁöÑ\n",
            "[06:22.000 --> 06:24.000] ÁÑ∂ÂæåÂÜç‰æÜÂ∞±‰πò‰ª•2Â∞±ËÆä\n",
            "[06:24.000 --> 06:26.000] 480\n",
            "[06:26.000 --> 06:28.000] Á≠âÊñºÊòØÁ¨¨‰∏âÂπ¥\n",
            "[06:28.000 --> 06:30.000] Â∞±Á∂ìÈÅéÂÖ©Âπ¥Â∫¶\n",
            "[06:30.000 --> 06:32.000] Á∂ìÈÅé‰∏âÂÄãÂπ¥Â∫¶\n",
            "[06:32.000 --> 06:34.000] Á∂ìÈÅé‰∏âÂÄãÂπ¥Â∫¶ËÆäÊàê960\n",
            "[06:34.000 --> 06:36.000] ÂÜçÁ∂ìÈÅé\n",
            "[06:36.000 --> 06:38.000] ÈÄôÂÄãÁ¨¨ÂõõÂÄãÂπ¥Â∫¶\n",
            "[06:38.000 --> 06:40.000] Â∞±ÊòØ\n",
            "[06:40.000 --> 06:42.000] 1920\n",
            "[06:42.000 --> 06:44.000] Âà∞Á¨¨‰∫îÂÄãÂπ¥Â∫¶Êâç3840\n",
            "[06:44.000 --> 06:46.000] ‰ΩÜÊòØÊàëÁèæÂú®ÊòØÁ¨¨ÂõõÂÄãÂπ¥Â∫¶\n",
            "[06:46.000 --> 06:48.000] 1920\n",
            "[06:48.000 --> 06:50.000] ÂØ¶Èöõ‰∏äÈÇÑÊØî100%ÈÇÑÂ•Ω\n",
            "[06:50.000 --> 06:52.000] ÈÇ£‰Ω†Ë™™\n",
            "[06:52.000 --> 06:54.000] ÂÄãËÇ°Ë¶ÅË≥∫100%\n",
            "[06:54.000 --> 06:56.000] ÈÉΩ‰∏çÂÆπÊòì\n",
            "[06:56.000 --> 06:58.000] Áï∂ÁÑ∂ÂæàÂ§ö‰∫∫Ë™™‰∏çÂÆπÊòìÂï¶\n",
            "[06:58.000 --> 07:00.000] ÂèØÊòØÊàëÂÄã‰∫∫Ë™çÁÇ∫ÊòØÊúâÊ©üÊúÉ\n",
            "[07:00.000 --> 07:02.000] ÊàëÁúãÈÅéÈÄôÂÄã\n",
            "[07:02.000 --> 07:04.000] Âú®ÈÄôÂÄã‰ΩéÂç°‰∏äÈù¢poÈÅéÈÄôÈ∫ºÂ§öÁøªÂÄçËÇ°\n",
            "[07:04.000 --> 07:06.000] ÊáâË©≤‰∏çÊúÉÂÜçÁõ∏‰ø°\n",
            "[07:06.000 --> 07:08.000] Ë™™‰∏çÂèØËÉΩÊâæÂà∞ÁøªÂÄçËÇ°\n",
            "[07:08.000 --> 07:10.000] ÈÄô‰ª∂‰∫ãÊÉÖ‰∫ÜÂï¶\n",
            "[07:10.000 --> 07:12.000] ÊàëÂÄã‰∫∫Ë™çÁÇ∫ÊòØ\n",
            "[07:12.000 --> 07:14.000] ‰∏çË¶ÅË¨õË™™\n",
            "[07:14.000 --> 07:16.000] ÁúüÁöÑÊòØ‰∏çÂèØËÉΩÊàñÊòØÂæàÂõ∞Èõ£\n",
            "[07:16.000 --> 07:18.000] ‰ΩÜÊòØÊàëË™çÁÇ∫Ë™™‰Ω†Âè™Ë¶Å‰ªîÁ¥∞Êâæ\n",
            "[07:18.000 --> 07:20.000] ÊòØÊúâÊ©üÊúÉÁöÑ\n",
            "[07:20.000 --> 07:22.000] Êàë‰πü‰∏çÊï¢ÊääÊè°\n",
            "[07:22.000 --> 07:24.000] Ë∑ü‰Ω†Ë™™\n",
            "[07:24.000 --> 07:26.000] ÁµïÂ∞çÊØèÂπ¥ÈÉΩÊâæÂæóÂà∞ÊàñÊòØÊÄéÈ∫ºÊ®£\n",
            "[07:26.000 --> 07:28.000] Êàë‰πü‰∏çÊï¢Ë¨õ\n",
            "[07:28.000 --> 07:30.000] ‰ΩÜÊòØÂ¶ÇÊûú‰Ω†Áî®ÂøÉÊâæ\n",
            "[07:30.000 --> 07:32.000] ÊàëË™çÁÇ∫ÊòØÊúâÊ©üÊúÉÊâæÂà∞\n",
            "[07:32.000 --> 07:34.000] ÁøªÂÄçËÇ°\n",
            "[07:34.000 --> 07:36.000] ‰ΩÜÊòØÁøªÂÄçËÇ°Êâæ\n",
            "[07:36.000 --> 07:38.000] ÊàëÂÄã‰∫∫Ë™çÁÇ∫\n",
            "[07:38.000 --> 07:40.000] ÂÄãËÇ°ÊúÉÁ∞°ÂñÆ‰∏ÄÈªû\n",
            "[07:40.000 --> 07:42.000] ‰ΩÜÊòØ‰Ω†Ë¶ÅÊâæÂà∞\n",
            "[07:42.000 --> 07:44.000] ‰Ω†Ë¶ÅÊÉ≥Ëæ¶Ê≥ïËÆìÂ∏ÇÂÄº\n",
            "[07:44.000 --> 07:46.000] ‰πüÂ∞±ÊòØ‰Ω†ÁöÑÊï¥ÂÄãË≥áÁî¢Â¢ûÂä†‰∏ÄÂÄç\n",
            "[07:46.000 --> 07:48.000] ÈÄôÂÄãÊòØÂõ∞Èõ£Âú®Âõ∞Èõ£\n",
            "[07:48.000 --> 07:50.000] ÊàëÂÄëË¨õÂ∑¥Ëè≤Áâπ\n",
            "[07:50.000 --> 07:52.000] Èï∑ÊúüÊòØ20%Â∑¶Âè≥\n",
            "[07:52.000 --> 07:54.000] ‰ΩÜÊàëÂÄë\n",
            "[07:54.000 --> 07:56.000] ÂèØ‰ª•ÂÅöÂà∞100%\n",
            "[07:56.000 --> 07:58.000] ÈÄôÂÄãÂæàÂ§ßÁöÑÂéüÂõ†ÂÖ∂ÂØ¶ÊòØ\n",
            "[07:58.000 --> 08:00.000] Á¨¨‰∏ÄÂÄãÊàëÂÄëÂÅöÁöÑÊòØ\n",
            "[08:00.000 --> 08:02.000] ÊØîËºÉË≥áÁî¢\n",
            "[08:02.000 --> 08:04.000] ‰πüÂ∞±ÊòØË™™\n",
            "[08:04.000 --> 08:06.000] Ë≥áÊú¨È°çÊØîËºÉÂ∞èÁöÑÂÖ¨Âè∏\n",
            "[08:06.000 --> 08:08.000] ÂêÑ‰ΩçÈÉΩÁü•ÈÅìË≥áÊú¨È°çÂ∞èÂÖ¨Âè∏Êúâ‰ªÄÈ∫ºÂ•ΩËôï\n",
            "[08:08.000 --> 08:10.000] ‰ªñÁöÑ\n",
            "[08:10.000 --> 08:12.000] ÈÄôÂÄãË¶ñÊ≥ÅÊØîËºÉ‰∏çÈÄèÊòé\n",
            "[08:12.000 --> 08:14.000] ‰Ω†ÂÉèÂè∞Á©çÈõªÈÄ£ÁôºÁßë\n",
            "[08:14.000 --> 08:16.000] È¥ªÊµ∑ÈÄô‰∫õ\n",
            "[08:16.000 --> 08:18.000] Â§ñË≥áÊó©Â∞±ÁúãÈÄèÈÄè‰∫Ü\n",
            "[08:18.000 --> 08:20.000] ÊØèÂ§©Â§öÂ∞ë‰∫∫\n",
            "[08:20.000 --> 08:22.000] Â§öÂ∞ë‰∫∫ÂäõÂéªËßÄÂØü\n",
            "[08:22.000 --> 08:24.000] ÈÄôÂÄãÂÖ¨Âè∏\n",
            "[08:24.000 --> 08:26.000] ÁîöËá≥ÊàëË∑ü‰Ω†ÂÄëË¨õ\n",
            "[08:26.000 --> 08:28.000] ÈÇ£ÂÄãÁ†îÁ©∂Âì°\n",
            "[08:28.000 --> 08:30.000] Ë∑üÈÇ£ÂÄã\n",
            "[08:30.000 --> 08:32.000] ÁôºË®Ä‰∫∫\n",
            "[08:32.000 --> 08:34.000] ÂèØ‰ª•Ë™™\n",
            "[08:34.000 --> 08:36.000] Â¶ÇÊûúË™™Â∏∏Ë¶ãÈù¢ÁöÑË©±\n",
            "[08:36.000 --> 08:38.000] Â∞±ÊòØÁÜüÂà∞‰∏çË°å\n",
            "[08:38.000 --> 08:40.000] ‰ªñÂè´‰ªÄÈ∫ºÂêçÂ≠ó\n",
            "[08:40.000 --> 08:42.000] ÈÄôÂÄãË®òËÄÖÊàñÊòØÈÄôÂÄã\n",
            "[08:42.000 --> 08:44.000] Á†îÁ©∂Âì°Âè´‰ªÄÈ∫ºÂêçÂ≠ó\n",
            "[08:44.000 --> 08:46.000] ‰ªñÈÉΩÁü•ÈÅì\n",
            "[08:46.000 --> 08:48.000] Âõ†ÁÇ∫Â§™Â∏∏Ë¶ãÈù¢‰∫Ü\n",
            "[08:48.000 --> 08:50.000] ‰ªñ‰∫ÜËß£‰ªñÂÖ¨Âè∏\n",
            "[08:50.000 --> 08:52.000] ‰ªñ‰∏ÄÂÆöË¶ÅË∑üÁôºË®Ä‰∫∫\n",
            "[08:52.000 --> 08:54.000] ‰∫§Êèõ‰ªñÁöÑÂøÉÂæóÊÑèË¶ã\n",
            "[08:54.000 --> 08:56.000] ÊâÄ‰ª•ÈÄôÂÄãÊÉÖÊ≥Å‰∏ã\n",
            "[08:56.000 --> 08:58.000] ‰Ω†Â∞±ÊÄéÈ∫ºÊ®£\n",
            "[08:58.000 --> 09:00.000] ‰Ω†ÁöÑË≥áË®äÁöÑ\n",
            "[09:00.000 --> 09:02.000] È†òÂÖàÂ∫¶Â∞±ÊúÉ\n",
            "[09:02.000 --> 09:04.000] ÂæàÂÆπÊòìËº∏Áµ¶ÈÄô‰∫õ\n",
            "[09:04.000 --> 09:06.000] Â∞àÊ•≠‰∫∫Âì°\n",
            "[09:06.000 --> 09:08.000] ‰ªñÂÄëÁ†îÁ©∂ÈÉ®Ê¥æÈÇ£È∫ºÂ§ö‰∫∫Âéª\n",
            "[09:08.000 --> 09:10.000] Ë®òËÄÖÊ¥æÈÇ£È∫ºÂ§ö‰∫∫Âéª\n",
            "[09:10.000 --> 09:12.000] ‰ªñ‰∫ÜËß£ÁöÑÊù±Ë•øÂ∑≤Á∂ìÊØî‰Ω†Â§ö\n",
            "[09:12.000 --> 09:14.000] ‰Ω†Âú®ÂéªÂà§Êñ∑ÁöÑÊôÇÂÄô\n",
            "[09:14.000 --> 09:16.000] ÂèØËÉΩÈÉΩÊòØ‰∫åÊâã‰∏âÊâãÁöÑÊù±Ë•ø\n",
            "[09:16.000 --> 09:18.000] ‰Ω†ÁúãÂà∞Êñ∞ËÅûÁöÑÊôÇÂÄôÂ∑≤Á∂ì‰æÜ‰∏çÂèä‰∫Ü\n",
            "[09:18.000 --> 09:20.000] ÈÇ£ÊÄéÈ∫ºËæ¶\n",
            "[09:20.000 --> 09:22.000] Êúâ‰ªÄÈ∫ºÊù±Ë•øÊòØÊàëÂÄë\n",
            "[09:22.000 --> 09:24.000] ÂèØ‰ª•Ë¥èÈÄô‰∫õÁ†îÁ©∂Âì°\n",
            "[09:24.000 --> 09:26.000] ÊàñËÄÖÊòØË®òËÄÖÁöÑ‰∏ÄÂÄã\n",
            "[09:26.000 --> 09:28.000] Ë∑ü‰ªñÂÄë\n",
            "[09:28.000 --> 09:30.000] ÊØîËºÉÁöÑ‰∏ÄÂÄãÁãÄÊ≥Å\n",
            "[09:30.000 --> 09:32.000] ‰πüÂ∞±ÊòØË™™ÈÄôÁ®ÆÂ∞èËÇ°Êú¨\n",
            "[09:32.000 --> 09:34.000] Â∞èËÇ°Êú¨ÁöÑ‰Ω†Ë™çÁÇ∫\n",
            "[09:34.000 --> 09:36.000] Êúâ‰∫∫ÊúÉÂéªÁ†îÁ©∂ÂÆÉÂóé\n",
            "[09:36.000 --> 09:38.000] ‰ªñ‰∏ÄÂÆ∂ÂÖ¨Âè∏Ë≥áÊú¨ÁöÑ3ÂÑÑ\n",
            "[09:38.000 --> 09:40.000] ‰Ω†ÊääÂÆÉÂÖ®ÈÉ®Ë≤∑‰∏ã‰æÜ\n",
            "[09:40.000 --> 09:42.000] ÊØîÂ¶ÇË™™ÂÆÉÁèæÂú®ÊòØ10Â°äÈå¢\n",
            "[09:42.000 --> 09:44.000] ÂÆÉ3ÂÑÑ\n",
            "[09:44.000 --> 09:46.000] Â¶ÇÊûúÊòØ\n",
            "[09:46.000 --> 09:48.000] 100Â°äÂÆÉ30ÂÑÑ\n",
            "[09:48.000 --> 09:50.000] ÂæàÂ§öÁöÑÂü∫Èáë\n",
            "[09:50.000 --> 09:52.000] ÂÆÉË¶ÅÁöÑÈ°çÂ∫¶\n",
            "[09:52.000 --> 09:54.000] ‰∏çÊúÉÈÄôÈ∫ºÂ∞ë\n",
            "[09:54.000 --> 09:56.000] ËÇ°Êú¨ÂÆÉ‰∏çË¶ÅÈÇ£È∫ºÂ∞èÁöÑÂÖ¨Âè∏\n",
            "[09:56.000 --> 09:58.000] Âõ†ÁÇ∫ÂÆÉ\n",
            "[09:58.000 --> 10:00.000] Èö®‰æø‰∏ÄÁ≠ÜÈå¢ÂÆÉÂ∞±ÊääÂÆÉÂêÉÊéâ‰∫Ü\n",
            "[10:00.000 --> 10:02.000] Â∞çÂÆÉÈÄ†ÊàêÁöÑ\n",
            "[10:02.000 --> 10:04.000] ÊïàÁõäÊòØ‰∏çÂ§ßÁöÑ\n",
            "[10:04.000 --> 10:06.000] ÊâÄ‰ª•ÂÆÉÊúÉÁ†îÁ©∂Â§ßÂûãÁöÑÂÖ¨Âè∏\n",
            "[10:06.000 --> 10:08.000] Â§ßÂûãÁöÑÂÖ¨Âè∏ÊâçËÉΩËÆìÂÆÉË≥áÁî¢Â¢ûÂÄº\n",
            "[10:08.000 --> 10:10.000] Â∞çÂêß\n",
            "[10:10.000 --> 10:12.000] ÂÆÉÂéªÁÇíÈÄôÁ®ÆÂ∞èÂÖ¨Âè∏\n",
            "[10:12.000 --> 10:14.000] Â∞çÂÆÉ‰æÜË¨õÂÆÉÂÖ∂ÂØ¶\n",
            "[10:14.000 --> 10:16.000] ÊÑèÁæ©‰∏çÂ§ß\n",
            "[10:16.000 --> 10:18.000] ÊâÄ‰ª•ÂÆÉÂÄëÂ∞±ÊòØ‰∏ªË¶Å\n",
            "[10:18.000 --> 10:20.000] ‰ΩàÂ±ÄÂú®Â§ßÂÖ¨Âè∏\n",
            "[10:20.000 --> 10:22.000] ÈÇ£Â∞èÂÖ¨Âè∏ËÆä‰ªÄÈ∫º\n",
            "[10:22.000 --> 10:24.000] ÊàëÂÄëÈÄô‰∫õÊï£Êà∂ÊúâÂà©\n",
            "[10:24.000 --> 10:26.000] ÊâÄ‰ª•‰Ω†ÁúãÊàëÁôºÂÆ∂\n",
            "[10:26.000 --> 10:28.000] Á¨¨‰∏ÄÂÄãÊòØ\n",
            "[10:28.000 --> 10:30.000] ÈÄôÂÄã‰∏≠È£õËà™\n",
            "[10:30.000 --> 10:32.000] ‰∏≠È£õËà™ÂêÑ‰ΩçÈÉΩÁü•ÈÅì\n",
            "[10:32.000 --> 10:34.000] ËÅΩÈÅéÂæàÂ§öÊ¨°\n",
            "[10:34.000 --> 10:36.000] ‰∏≠È£õËà™ÂÆÉÁöÑÈÄôÂÄã\n",
            "[10:36.000 --> 10:38.000] Ë≥áÊú¨È°ç\n",
            "[10:38.000 --> 10:40.000] ÊàëÂÄëË¨õËÇ°Êú¨\n",
            "[10:40.000 --> 10:42.000] ËÇ°Êú¨ÊòØÂ§öÂ∞ë\n",
            "[10:42.000 --> 10:44.000] ÂÖ∂ÂØ¶ÂÆÉÁöÑËÇ°Êú¨Êâç14.29ÂÑÑ\n",
            "[10:44.000 --> 10:46.000] ÈÄôÂÄã\n",
            "[10:46.000 --> 10:48.000] Âè∞Á©çÈõªÊØîËÅØÈõª\n",
            "[10:48.000 --> 10:50.000] ÊØîËÅØÁôºÁßëÈÄôÁ®ÆÁ¥ÖÊµ∑\n",
            "[10:50.000 --> 10:52.000] ÈÄôÁ®ÆÂ∞ëÁöÑÂèØÊÜêÂà∞ÂÆ∂\n",
            "[10:52.000 --> 10:54.000] 14.Â§öÂÑÑ\n",
            "[10:54.000 --> 10:56.000] ÈÄôÂÖ¨Âè∏Ê†πÊú¨\n",
            "[10:56.000 --> 10:58.000] ÊàëÈÇ£ÊôÇÂÄôË≤∑20ÂπæÂ°ä\n",
            "[10:58.000 --> 11:00.000] 20ÂπæÂ°äÁöÑË©±ÂÆÉÂ∏ÇÂÄº‰πüÊâç2.31\n",
            "[11:00.000 --> 11:02.000] ÈÄôÊ†πÊú¨Ê≤íÊúâ‰ªÄÈ∫º‰∫∫ÊúÉÂéªË≤∑\n",
            "[11:02.000 --> 11:04.000] ÈÇ£ÊâÄ‰ª•ÈÄôÂÄãËá™ÁÑ∂‰∏çÊúÉ\n",
            "[11:04.000 --> 11:06.000] Êúâ‰ªÄÈ∫º‰∫∫Á†îÁ©∂\n",
            "[11:06.000 --> 11:08.000] Â∞±ÂæàÂÆπÊòìË≥∫Âà∞ÁøªÂÄç\n",
            "[11:08.000 --> 11:10.000] Âõ†ÁÇ∫ÊàëÂÄëÈ†òÂÖà\n",
            "[11:10.000 --> 11:12.000] Ë∑üÂ∏ÇÂ†¥ÁöÑÊ∂àÊÅØÊòØÁ¨¨‰∏ÄÊâã\n",
            "[11:12.000 --> 11:14.000] Á¨¨‰∏ÄÊâã\n",
            "[11:14.000 --> 11:16.000] ÈÄôÁ®ÆËÇ°Á•®\n",
            "[11:16.000 --> 11:18.000] Â∞èËÇ°Êú¨ÁöÑËÇ°Á•®Âú®Êº≤ÁöÑÊôÇÂÄô\n",
            "[11:18.000 --> 11:20.000] ÂÆÉ‰πüÊòØÈÇÑÊòØ‰∏ÄÊ®£\n",
            "[11:20.000 --> 11:22.000] Ë∑üÂ§ßËÇ°Á•®‰∏ÄÊ®£\n",
            "[11:22.000 --> 11:24.000] ÈÉΩÊòØÊúÉÊúâÊ©üÊúÉËÆäÊ≥®ÊÑèËÇ°\n",
            "[11:24.000 --> 11:26.000] ÂÑ≤ÂÄºËÇ°ÁöÑ\n",
            "[11:26.000 --> 11:28.000] ‰ΩÜÊòØÂ§ßËÇ°Á•®ÊØîËºÉ‰∏çÂÆπÊòì\n",
            "[11:28.000 --> 11:30.000] ‰Ω†ÊúâÁúãÈÅé‰ªÄÈ∫ºÂè∞Á©çÈõªËÆäÂÑ≤ÂÄº\n",
            "[11:30.000 --> 11:32.000] ÊàëÂÄã‰∫∫Ë™çÁÇ∫\n",
            "[11:32.000 --> 11:34.000] ÊàëÂÄã‰∫∫ÈÄôÂπæÂπ¥‰æÜ\n",
            "[11:34.000 --> 11:36.000] ÈÄôÂçÅÂπ¥‰æÜÂ•ΩÂÉè\n",
            "[11:36.000 --> 11:38.000] ÈÄô‰∫åÂçÅÂπ¥‰æÜÂ•ΩÂÉèÊ≤íÊúâÁúãÈÅé\n",
            "[11:38.000 --> 11:40.000] Âè∞Á©çÈõªËÆäÂÑ≤ÂÄº\n",
            "[11:40.000 --> 11:42.000] ÂÉèÂ∞èËÇ°Á•®ÂæàÂÆπÊòìËÆäÂÑ≤ÂÄº\n",
            "[11:42.000 --> 11:44.000] ÂæàÂÆπÊòìËÆäÂÑ≤ÂÄºÁöÑÊôÇÂÄô\n",
            "[11:44.000 --> 11:46.000] Â∞±ÊòØË¶ÅËá™Áµê\n",
            "[11:46.000 --> 11:48.000] ÈÇ£ÈÄôÂÄãÂÖ¨Âè∏\n",
            "[11:48.000 --> 11:50.000] ÂÉèÈÄôÂÄã‰∏≠ÈùûÂ∏∏ÁöÑÊôÇÂÄô\n",
            "[11:50.000 --> 11:52.000] ÊàëË®òÂæóÂ•ΩÂÉè‰πüÊúâËá™Áµê\n",
            "[11:52.000 --> 11:54.000] ‰πüÊòØÂú®Êº≤ÁöÑÊôÇÂÄô‰∏çÈåØ\n",
            "[11:54.000 --> 11:56.000] ÁÑ∂ÂæåËá™Áµê‰πü‰∏çÈåØ\n",
            "[11:56.000 --> 11:58.000] ÁÑ∂ÂæåÂèàÊº≤‰∏äÂéª\n",
            "[11:58.000 --> 12:00.000] ÈÇ£ÈÇÑÊúâÂÉè‰ªÄÈ∫ºÂÉèÊàë‰πãÂâçË≤∑ÁöÑÊôÇÂÄô\n",
            "[12:00.000 --> 12:02.000] Ë≤∑Âè∞ËèØ\n",
            "[12:02.000 --> 12:04.000] ÈÇ£Âè∞ËèØÁúüÁöÑÂ∞±ÊòØÈù†\n",
            "[12:04.000 --> 12:06.000] Ëá™ÁµêË≥∫Âà∞Â§ßÈå¢\n",
            "[12:06.000 --> 12:08.000] ÁúüÁöÑÊòØÈù†Ëá™ÁµêË≥∫Âà∞Â§ßÈå¢\n",
            "[12:08.000 --> 12:10.000] ‰ªñ‰πüÊòØÊîØÊçß‰∫Ü14Â§öÂÑÑÁöÑËÇ°Á•®\n",
            "[12:10.000 --> 12:12.000] ÈÇ£ÊôÇÂÄôÈï∑Ê¶ÆÊèõÂè∞ËèØ\n",
            "[12:12.000 --> 12:14.000] ÈÇ£Âè∞ËèØ‰∏ÄÁõ¥Êº≤Êº≤Êº≤Êº≤\n",
            "[12:14.000 --> 12:16.000] Êº≤Âà∞‰∫îÊúàÂ§öÂêß\n",
            "[12:16.000 --> 12:18.000] ‰ªñÂõ†ÁÇ∫‰ªñÊº≤ÂπÖÂ§™Â§ß\n",
            "[12:18.000 --> 12:20.000] ‰ªñËÄÅÈóÜË™™‰∏ÄÂè•Ë©±\n",
            "[12:20.000 --> 12:22.000] ‰∏ÄÂºµ‰∏çË≥£ÂÖ∂Ê•µÂÄº\n",
            "[12:22.000 --> 12:24.000] ÂêÑ‰ΩçÂ§ßÊ¶ÇÈÉΩËÉå\n",
            "[12:24.000 --> 12:26.000] ÁµêÊûúÂë¢\n",
            "[12:26.000 --> 12:28.000] ËÇ°ÂÉπ‰∏ÄÁõ¥Êº≤ÂÅúÊº≤ÂÅú\n",
            "[12:28.000 --> 12:30.000] ÁÑ∂ÂæåÈáçÈªûÊòØÊàëÊàëÂπæ‰πé\n",
            "[12:30.000 --> 12:32.000] ÈÇ£ÂÄãÊôÇÂÄôÈï∑Ê¶ÆË≥£ÊéâÂπæ‰πéÈÉΩ\n",
            "[12:32.000 --> 12:34.000] Â§ßÊ¶ÇÁôæÂàÜ‰πãÂÖ≠ÂçÅÁöÑËÇ°Á•®ÈÉΩÂ£ìÂè∞ËèØ\n",
            "[12:34.000 --> 12:36.000] ÊâÄ‰ª•ÊàëÊòØ\n",
            "[12:36.000 --> 12:38.000] Âπæ‰πéÊòØ‰∏ÄÂÄãall inÁöÑÁãÄÊ≥Å\n",
            "[12:38.000 --> 12:40.000] Êàëall inÂÖ®ÈÉ®ÈÉΩÊòØË°åÈÅ†ËÇ°\n",
            "[12:40.000 --> 12:42.000] ÁÑ∂ÂæåÂë¢\n",
            "[12:42.000 --> 12:44.000] ÁôæÂàÜ‰πãÂÖ≠ÂçÅÊòØÂè∞ËèØ\n",
            "[12:44.000 --> 12:46.000] ÁµêÊûúÂë¢\n",
            "[12:46.000 --> 12:48.000] ‰ªñËÄÅÈóÜÂèàË¨õÈÄôÂè•Ë©±ÂèàÁ¥Ö‰∫Ü\n",
            "[12:48.000 --> 12:50.000] Â∞±‰∏ÄÁõ¥Êº≤ÂÅúÊº≤ÂÅú\n",
            "[12:50.000 --> 12:52.000] ÈáçÈªû‰æÜ‰∫Ü‰ªñË¶ÅËá™Áµê\n",
            "[12:52.000 --> 12:54.000] ÈÇ£ÊàëË®òÂæóÈÇ£ÂÄãÊôÇÂÄôËá™Áµê‰πüÊòØ\n",
            "[12:54.000 --> 12:56.000] ‰∏ÄÂÄãÊúàÂ∞±Ë≥∫ÂçÅÂπæÂ°ä\n",
            "[12:56.000 --> 12:58.000] ÈñãÁé©Á¨ë\n",
            "[12:58.000 --> 13:00.000] ‰ªñÂ∑≤Á∂ìÊº≤ÈÄôÈ∫ºÂ§öÊ†π‰∫Ü\n",
            "[13:00.000 --> 13:02.000] ‰ªñÈÇÑÂÖ¨‰ΩàÂçÅÂπæÂ°ä\n",
            "[13:02.000 --> 13:04.000] ÈÄôËÇ°ÂÉπÊúÉË∑ü‰Ω†ÁïôÊÉÖÂóé\n",
            "[13:04.000 --> 13:06.000] ÊâÄ‰ª•\n",
            "[13:06.000 --> 13:08.000] ÈÄôÁ®ÆÂ∞±Âè´ÂÅö\n",
            "[13:08.000 --> 13:10.000] Â§©ÊôÇÂú∞Âà©‰∫∫Âíå\n",
            "[13:10.000 --> 13:12.000] ÁúüÁöÑÊòØÂ§©ÊôÇÂú∞Âà©‰∫∫Âíå\n",
            "[13:12.000 --> 13:14.000] ‰Ω†ÊâçÊúâÈÄôÁ®ÆÂçÅÂÄçËÇ°ÁöÑÈÄôÁ®Æ\n",
            "[13:14.000 --> 13:16.000] ÈÄôÁ®Æ‰∫´Âèó\n",
            "[13:16.000 --> 13:18.000] ÈÄôÂÄã‰∏ÄÁîü‰Ω†\n",
            "[13:18.000 --> 13:20.000] ‰∫´ÂèóÂÄã‰∏ÄÊ¨°ÂÖ∂ÂØ¶\n",
            "[13:20.000 --> 13:22.000] Â∞±Ë∂≥‰∫ÜÂï¶\n",
            "[13:22.000 --> 13:24.000] Â¶ÇÊûú‰Ω†ÁúüÁöÑÊòØ\n",
            "[13:24.000 --> 13:26.000] ‰∏ãÂæàÂ§ßÈáèÁöÑÊôÇÂÄôÊàëÈÇ£ÊôÇÂÄôÊòØ\n",
            "[13:26.000 --> 13:28.000] ‰∏ãÂæàÂ§ßÈáèÈÇ£ÊôÇÂÄôÊàëÂ∏≥Èù¢Áç≤Âà©Â∞±\n",
            "[13:28.000 --> 13:30.000] ÂçÉËê¨\n",
            "[13:30.000 --> 13:32.000] ÊàëÈÄôËº©Â≠ê‰πüÊ≤íÊúâÊÉ≥ÈÅé\n",
            "[13:32.000 --> 13:34.000] ÊàëÂèØ‰ª•Âú®ÈÄôÈ∫ºÁü≠ÁöÑÊôÇÈñì\n",
            "[13:34.000 --> 13:36.000] ÁàÜÂà∞‰∏ÄÂÄãÂçÅÂÄçËÇ°\n",
            "[13:36.000 --> 13:38.000] ÈÇ£ÁîöËá≥ÊòØË≥£Âú®È´òÈªû\n",
            "[13:38.000 --> 13:40.000] ÈÇ£Ë≥£Âú®È´òÈªûÈÇ£ÂÄãÁúüÁöÑÂ∞±ÊòØË¶Å\n",
            "[13:40.000 --> 13:42.000] Ë≥£Âá∫Â±±Ëó•ÂäçÊâÄ‰ª•ÊàëË™™\n",
            "[13:42.000 --> 13:44.000] Ë≥£Âá∫Â±±Ëó•Âäç‰Ω†Â¶ÇÊûúË™™\n",
            "[13:44.000 --> 13:46.000] ‰æÜÈÄôÂÄãÁæ§ÁµÑ\n",
            "[13:46.000 --> 13:48.000] ‰æÜËÅΩÈÄôÂÄãÈü≥Ê™îÁúüÁöÑÊúâÂ≠∏Âà∞‰ªÄÈ∫º\n",
            "[13:48.000 --> 13:50.000] ÊàëË™çÁÇ∫Á¨¨‰∏ÄÂÄã‰Ω†Â≠∏ÁöÑÂ∞±ÊòØË≥£Âá∫Â±±Ëó•Âäç\n",
            "[13:50.000 --> 13:52.000] Á¨¨‰∫åÂÄã‰Ω†Ë¶ÅÂ≠∏ÁöÑ\n",
            "[13:52.000 --> 13:54.000] Â∞±ÊòØÊú¨Ë≥™ËÆäÂåñ\n",
            "[13:54.000 --> 13:56.000] ÈÇ£ÂÖ∂‰ªñÁöÑÂÖ∂ÂØ¶\n",
            "[13:56.000 --> 13:58.000] ÈÉΩÂ§ßÂêåÂ∞èÁï∞\n",
            "[13:58.000 --> 14:00.000] Â∞±Â§ßÈÅìËá™Ëß£ÂæàÂ§öÊù±Ë•øÈÉΩÊòØ\n",
            "[14:00.000 --> 14:02.000] Â∞±ÊòØ‰Ω†Áî®\n",
            "[14:02.000 --> 14:04.000] È°û‰ººÁî®ËÜùËìã\n",
            "[14:04.000 --> 14:06.000] Â∞±Ë¨õËÜùËìãÊ≥ïÂâá\n",
            "[14:06.000 --> 14:08.000] ‰∏çË¶ÅÁî®ËÖ¶Áî®ËÖ¶Â∞±Â§™\n",
            "[14:08.000 --> 14:10.000] Ë§áÈõúÈÇ£ÂÄãËÖ¶ÊúÉÈ®ô‰Ω†\n",
            "[14:10.000 --> 14:12.000] ËÖ¶ÊúÉÈ®ô‰Ω†\n",
            "[14:12.000 --> 14:14.000] ÂæàÂ§öÊù±Ë•ø‰ªñÊúÉ‰∏ÄÁõ¥‰∏çÊñ∑ÁöÑÂéª\n",
            "[14:14.000 --> 14:16.000] Âπ≤Êìæ‰Ω†\n",
            "[14:16.000 --> 14:18.000] ÈÇ£‰∏çÂ∞çÁµïÂ∞çÂ∞±ÊòØ\n",
            "[14:18.000 --> 14:20.000] Â§ßÈÅìËá™Ëß£\n",
            "[14:20.000 --> 14:22.000] ÊàëÂÄëË¨õÂ§ßÈÅìËá™Ëß£‰ªÄÈ∫ºÊÑèÊÄù\n",
            "[14:22.000 --> 14:24.000] ‰Ω†Âú®Ë∑Ø‰∏äÁúãÂà∞‰∏ÄÂÄã\n",
            "[14:24.000 --> 14:26.000] Â∏•Âì•ÁúãÂà∞‰∏ÄÂÄãÁæéÂ•≥\n",
            "[14:26.000 --> 14:28.000] ‰Ω†\n",
            "[14:28.000 --> 14:30.000] Á¨¨‰∏ÄÂÄãÊÑüË¶∫ÊòØ‰ªÄÈ∫º\n",
            "[14:30.000 --> 14:32.000] Á¨¨‰∏ÄÂÄãÊÑüË¶∫ÈÄôÂÄãÂ•≥ÁîüÂæàÊúâ\n",
            "[14:32.000 --> 14:34.000] Ê∞£Ë≥™ÈÄôÂÄãÂ•≥ÁîüÂΩàÂ•ó\n",
            "[14:34.000 --> 14:36.000] ÂèØËÉΩË∑ü‰Ω†Ë¨õÂÖ©Âè•ÂΩàÂ•ó\n",
            "[14:36.000 --> 14:38.000] ÂæàÂ•Ω‰ΩéÈü≥ÈüøÂæàÂ•Ω\n",
            "[14:38.000 --> 14:40.000] ‰Ω†Â∞±ÊääÈÄôÂÄã‰ΩéÈü≥ÈüøË®ò‰Ωè\n",
            "[14:40.000 --> 14:42.000] ‰Ω†ÁúãÂà∞‰∏ÄÂÄãÈÄôÂÄã\n",
            "[14:42.000 --> 14:44.000] Â∏•Âì•‰ªñÈÄôÂÄã\n",
            "[14:44.000 --> 14:46.000] Ê∫´Êüî\n",
            "[14:46.000 --> 14:48.000] ÂÑíÈõÖÈÄôÂÄãÊàêË™û\n",
            "[14:48.000 --> 14:50.000] Êàë‰∏çÂ§™ÊúÉË¨õÁÑ∂Âæå\n",
            "[14:50.000 --> 14:52.000] ÈÄôÂÄã\n",
            "[14:52.000 --> 14:54.000] ËàâÂãïÈÄôÂÄã\n",
            "[14:54.000 --> 14:56.000] Áµ¶‰Ω†ÁöÑÈÄôÂÄãÈü≥ÈüøÈÉΩÂæàÈÅº\n",
            "[14:56.000 --> 14:58.000] ‰Ω†Á¨¨‰∏ÄÂÄãÈü≥ÈüøÂ∞±ÂæàÂ•Ω\n",
            "[14:58.000 --> 15:00.000] ÈÇ£‰Ω†‰∏çË¶ÅÈÄôÈ∫ºÁÑ°ËÅäË™™\n",
            "[15:00.000 --> 15:02.000] ‰Ω†ÈÇÑË¶ÅÂÜçÁøª‰ªñÈÅéÂéªÂÅö‰ªÄÈ∫º\n",
            "[15:02.000 --> 15:04.000] ‰∫ãÊÉÖÊàñËÄÖÊòØÂ≠òÊ¨æ\n",
            "[15:04.000 --> 15:06.000] Â§öÂ∞ë‰ªÄÈ∫ºÁöÑ‰∏çÁî®ÈÇ£È∫ºË§áÈõú\n",
            "[15:06.000 --> 15:08.000] ‰Ω†Â∞±Ë®òËëó‰ªñÁ¨¨‰∏ÄÂÄã\n",
            "[15:08.000 --> 15:10.000] Âç∞Ë±°ÁÑ∂ÂæåÂë¢\n",
            "[15:10.000 --> 15:12.000] Â∞±ÂÉèÊàëÁèæÂú®\n",
            "[15:12.000 --> 15:14.000] Âú®Ë¨õËÇ°Á•®Â∞±Ë®òËëó‰ªñÁ¨¨‰∏ÄÂÄã\n",
            "[15:14.000 --> 15:16.000] Âç∞Ë±°\n",
            "[15:16.000 --> 15:18.000] Áî®ËÜùËìãË¨õÂ§ßÊ¶Ç\n",
            "[15:18.000 --> 15:20.000] Â∞±ÂèØ‰ª•ÊäïË≥á\n",
            "[15:20.000 --> 15:22.000] ÊäïË≥áÊäïË≥áÊäïË≥á‰ª•Âæå‰Ω†Â∞±ÊúÉÊÖ¢ÊÖ¢\n",
            "[15:22.000 --> 15:24.000] ÁôºÁèæ‰ªñÁöÑÁãÄÊ≥Å\n",
            "[15:24.000 --> 15:26.000] ‰ªñÈÄôÂÄã\n",
            "[15:26.000 --> 15:28.000] ÂèØËÉΩ‰∏çÊòØË°®Èù¢ÊàñÊòØ‰ªÄÈ∫º\n",
            "[15:28.000 --> 15:30.000] ‰ªñÂÖ∂ÂØ¶ÊòØÊúâÈªûÂïèÈ°åÁöÑ\n",
            "[15:30.000 --> 15:32.000] ‰ªñÂèØËÉΩÈÄôÂÄã\n",
            "[15:32.000 --> 15:34.000] Ê≤íÊúâ‰ªÄÈ∫ºÂ≠òÊ¨æÊàñÊòØË™™\n",
            "[15:34.000 --> 15:36.000] ÈÇÑÊúâ‰ªÄÈ∫ºÂ•≥ÊúãÂèã\n",
            "[15:36.000 --> 15:38.000] ‰πãÈ°ûÁöÑ‰Ω†ÈÄôÂÄãÊôÇÂÄô\n",
            "[15:38.000 --> 15:40.000] ÁúãÂà∞ÂïèÈ°å‰Ω†ÂÜç‰æÜËß£Ê±∫\n",
            "[15:40.000 --> 15:42.000] ‰Ω†ÂÜç‰æÜÈÇÅÂá∫\n",
            "[15:42.000 --> 15:44.000] ‰ΩÜÊòØ‰Ω†Â∑≤Á∂ìÂÖàË≥∫‰∏ÄÊÆµ\n",
            "[15:44.000 --> 15:46.000] ÈÄôÂÄãÂ∞±ÊòØËÇ°Â∏Ç\n",
            "[15:46.000 --> 15:48.000] ÁöÑÂÅöÊ≥ï‰Ω†‰∏ÄÈñãÂßã\n",
            "[15:48.000 --> 15:50.000] ÁúãÂæóÂ§™Ë©≥Á¥∞ÁúãÂæóÂ§™\n",
            "[15:50.000 --> 15:52.000] Ê∑±ÂÖ•ÊàñÊòØÁúãÂæóÂ§™\n",
            "[15:52.000 --> 15:54.000] ÂÆåÁæéÁöÑÊôÇÂÄô\n",
            "[15:54.000 --> 15:56.000] ‰Ω†ÂèçËÄåÊäì‰∏çÂà∞ÈÇ£ÂÄã\n",
            "[15:56.000 --> 15:58.000] Áç≤Âà©ÁöÑÈáçÈªû\n",
            "[15:58.000 --> 16:00.000] ÁÇ∫‰ªÄÈ∫ºÂõ†ÁÇ∫ÈÇ£ÂÄãÁç≤Âà©ÁöÑÊôÇÂÄôÊòØ\n",
            "[16:00.000 --> 16:02.000] ÂÖ∂ÂØ¶Â§ßÂÆ∂ÈÉΩÊ≤íÊúâÁúãÂà∞\n",
            "[16:02.000 --> 16:04.000] ‰∏çÊòØÂè™Êúâ‰Ω†Ê≤íÁúãÂà∞\n",
            "[16:04.000 --> 16:06.000] ‰ªñÁàÜÂá∫‰æÜ‰∏Ä‰∫õÂïèÈ°å\n",
            "[16:06.000 --> 16:08.000] ÁöÑÊôÇÂÄôÊòØ\n",
            "[16:08.000 --> 16:10.000] ÈÄôÂÄãÈÄôÂÄãÈÄôÂÄã‰πãÂâçÊòØÂ§ßÂÆ∂\n",
            "[16:10.000 --> 16:12.000] Ê≤íÊúâÁúãÂà∞ÊâÄ‰ª•‰ªñÊúÉÊº≤\n",
            "[16:12.000 --> 16:14.000] ‰ªñÊúÉÊº≤ÊâÄ‰ª•‰Ω†\n",
            "[16:14.000 --> 16:16.000] ‰Ω†Á≠âÂà∞Â§ßÂÆ∂ÈÉΩÁúãÂà∞‰Ω†ÂÜç‰æÜË≥£\n",
            "[16:16.000 --> 16:18.000] ‰Ω†ÈÄôÊ®£‰Ω†‰πüÂèØ‰ª•\n",
            "[16:18.000 --> 16:20.000] Ë≥∫Âà∞Èå¢ÊâÄ‰ª•ËÜùËìãÊ≥ïÂâá\n",
            "[16:20.000 --> 16:22.000] Êúâ‰∫õ‰∫∫‰ªñÈëΩÁâõËßíÂ∞ñ\n",
            "[16:22.000 --> 16:24.000] ‰ªñÂ§™\n",
            "[16:24.000 --> 16:26.000] care‰∏Ä‰∫õÂïèÈ°å\n",
            "[16:26.000 --> 16:28.000] ÈÄôÂÄãËÄÅÈóÜ‰πãÂâçÊúâ‰ªÄÈ∫ºÂ©öÂ§ñÊÉÖ\n",
            "[16:28.000 --> 16:30.000] ‰Ω†ÂéªÁÆ°ËÄÅÈóÜÂ©öÂ§ñÊÉÖÂππ‰ªÄÈ∫º\n",
            "[16:30.000 --> 16:32.000] ‰∫∫ÂÆ∂ÊòØÁúãÂÖ¨Âè∏\n",
            "[16:32.000 --> 16:34.000] ÈÄôÂÄã‰πãÂâçÊúâÂÖßÁ∑ö‰∫§Êòì\n",
            "[16:34.000 --> 16:36.000] ÂÖßÁ∑ö‰∫§Êòì‰Ω†Ë¶ÅÁúã‰ªÄÈ∫ºÂÖßÁ∑ö‰∫§Êòì\n",
            "[16:36.000 --> 16:38.000] Êúâ‰∫õÊòØË®òËÄÖ\n",
            "[16:38.000 --> 16:40.000] ÈÇ£Á®Æ‰∏çÂ∞èÂøÉÁàÜÂá∫‰æÜ\n",
            "[16:40.000 --> 16:42.000] ÈÇÑÊòØ‰ªÄÈ∫ºÁöÑÈÇ£ÂÄã\n",
            "[16:42.000 --> 16:44.000] ÈÇ£ÂÄãÁÑ°ÈóúÁóõÈõÖÁöÑÂÖ∂ÂØ¶‰Ω†‰πü‰∏çÁî®Âéª\n",
            "[16:44.000 --> 16:46.000] Â§™Âú®‰πé‰Ω†ÁúãÈÇ£ÂÄã\n",
            "[16:46.000 --> 16:48.000] Âè∞ËèØËÄÅÈóÜ‰∏çÊòØ‰ªñ‰πüÊòØ\n",
            "[16:48.000 --> 16:50.000] Âæå‰æÜË¢´Ë¨õË™™‰ªñÂú®2020\n",
            "[16:50.000 --> 16:52.000] ÁöÑÊôÇÂÄôÊúâÂÖßÁ∑ö‰∫§Êòì\n",
            "[16:52.000 --> 16:54.000] ÊâçÂÖ©ÁôæËê¨\n",
            "[16:54.000 --> 16:56.000] ‰ΩÜÊòØ\n",
            "[16:56.000 --> 16:58.000] ÈÄôÂÄãÊúÉÂΩ±Èüø‰ªñËÇ°ÂÉπÁöÑÊº≤Âã¢\n",
            "[16:58.000 --> 17:00.000] ‰∏çÊúÉ‰ªñ‰∏ÄÊ®£Áµ¶‰Ω†\n",
            "[17:00.000 --> 17:02.000] Áµ¶‰Ω†ÂÄãÁøªÂçÅÂÄçÁï∂ÁÑ∂ÈÇ£ÂÄãÊôÇÂÄôÊòØ\n",
            "[17:02.000 --> 17:04.000] ÈÇÑÊ≤íÊúâ\n",
            "[17:04.000 --> 17:06.000] Áü•ÈÅìÈÄôÂÄã‰∫ãÊÉÖ\n",
            "[17:06.000 --> 17:08.000] Âè™ÊòØË™™Êàë\n",
            "[17:08.000 --> 17:10.000] Ë™çÁÇ∫ÈÄôÁ®ÆÈÉΩÊòØÁç®Á´ã‰∫ã‰ª∂\n",
            "[17:10.000 --> 17:12.000] ÂêÑ‰Ωç‰Ω†Ë¶ÅÂéªÁúãÁï∂ÊôÇ\n",
            "[17:14.000 --> 17:16.000] ‰∏ÄÂÄãÂ§ßÁúæË≥áË®äËÉΩÂ§†ÊäìÂà∞\n",
            "[17:16.000 --> 17:18.000] ÁöÑÊÉÖÊ≥Å\n",
            "[17:18.000 --> 17:20.000] ËÄå‰∏çÊòØ‰Ω†ÈëΩÁâõËßíÂäç\n",
            "[17:20.000 --> 17:22.000] ‰Ω†ÂæÄÂæÄÊúÉÈåØÈÅé\n",
            "[17:22.000 --> 17:24.000] Â§ßÁç≤Âà©\n",
            "[17:24.000 --> 17:26.000] ÂÜç‰æÜÂ∞±ÊòØ‰ªÄÈ∫ºÂú®Â≠óÁØÄ\n",
            "[17:26.000 --> 17:28.000] Â∞ç‰ªÄÈ∫ºÂÖ¨Âè∏ÊúÉÊØîËºÉ\n",
            "[17:28.000 --> 17:30.000] ÊúâÊêçÂÇ∑Â∞±ÊòØÂ∞çÈÇ£‰∫õ\n",
            "[17:30.000 --> 17:32.000] ËÖ∞È™®\n",
            "[17:32.000 --> 17:34.000] ÂÉèÊàëÂÄëË¨õÈÇ£ÂÄã\n",
            "[17:34.000 --> 17:36.000] 6405ÁöÑÈÇ£ÂÄãÊúàÊàê\n",
            "[17:36.000 --> 17:38.000] ÈÄôÂÄãÂú®ÁÇí‰ªÄÈ∫º\n",
            "[17:38.000 --> 17:40.000] ‰ªñÊòØÂú®ÁÇíÈÇ£ÂÖâÈõª\n",
            "[17:40.000 --> 17:42.000] ‰πãÂâç‰πüÊòØÂú®ÁÇíÂÖâÈõª\n",
            "[17:42.000 --> 17:44.000] GV200ÊÄéÈ∫ºÊ®£\n",
            "[17:44.000 --> 17:46.000] ÂèØÊòØÂêÑ‰Ωç‰Ω†Áúã\n",
            "[17:46.000 --> 17:48.000] ‰ªñÈÄôÂÄã10Êúà23‰ªñÂâµ‰∏ÄÂÄã\n",
            "[17:48.000 --> 17:50.000] 5Ëê¨4ÂçÉÂºµÁöÑÈáè\n",
            "[17:50.000 --> 17:52.000] ‰ª•Âæå\n",
            "[17:52.000 --> 17:54.000] ‰ªñÈÇÑÊúâÂú®‰∏äÂéª\n",
            "[17:54.000 --> 17:56.000] Â∞±‰∏ä‰∏çÂéª‰∫Ü\n",
            "[17:56.000 --> 17:58.000] ÊúÄÈ´òÂ∞±ÊòØ51\n",
            "[17:58.000 --> 18:00.000] Â§ßÊ¶Ç51Â°äÂ∑¶Âè≥51Â°äÈªû4\n",
            "[18:00.000 --> 18:02.000] Â∞±‰∏ä‰∏çÂéª‰∫Ü\n",
            "[18:02.000 --> 18:04.000] ÁÑ∂Âæå‰ªñÂÖ¨‰Ωà‰∏ÄÂÄãÂ≠óÁØÄ\n",
            "[18:04.000 --> 18:06.000] ÂÖ¨‰Ωà‰∏ÄÂÄãÂ≠óÁØÄ‰ª•ÂæåÊÄéÈ∫ºÊ®£\n",
            "[18:06.000 --> 18:08.000] ËÇ°ÂÉπÂ∞±ÊÖ¢ÊÖ¢ÂèàÈñãÂßã\n",
            "[18:08.000 --> 18:10.000] ÊÖ¢ÊÖ¢Ë∂®Á∑©\n",
            "[18:10.000 --> 18:12.000] Áï∂ÁÑ∂ÁèæÂú®ÈÇÑÊ≤íÊúâ\n",
            "[18:12.000 --> 18:14.000] Ë∑åÁ†¥‰ªñ‰πãÂâçÁöÑÈÄôÂÄã\n",
            "[18:14.000 --> 18:16.000] Ëµ∑Êº≤Èªû20ÂπæÂ°ä\n",
            "[18:16.000 --> 18:18.000] ÈÇ£ÊòØÂõ†ÁÇ∫‰ªÄÈ∫ºÈÄôÂÄãË©±È°åÈÇÑÂú®\n",
            "[18:18.000 --> 18:20.000] Ë©±È°åÈÇÑÂú®‰ªñÊúâË©±È°å\n",
            "[18:20.000 --> 18:22.000] ÁöÑ‰∏ÄÂÄãÂÑ™Âã¢\n",
            "[18:22.000 --> 18:24.000] ÂèØÊòØ‰Ω†Ë¶ÅÁü•ÈÅìË©±È°å‰∏ÄÁµêÊùü\n",
            "[18:24.000 --> 18:26.000] ÁöÑÊôÇÂÄôÈÇ£Â∞±ÊòØ‰ªñÁöÑÂä£Âã¢\n",
            "[18:26.000 --> 18:28.000] ÊâÄ‰ª•‰Ω†\n",
            "[18:28.000 --> 18:30.000] ÂêÑ‰Ωç‰∏çË¶ÅË™™\n",
            "[18:30.000 --> 18:32.000] ‰∏ÄÁõ¥Âü∑Ëëó\n",
            "[18:32.000 --> 18:34.000] Âú®ÈÄôÁ®ÆÊ≤íÊúâÁç≤Âà©ÁöÑËÇ°Á•®\n",
            "[18:34.000 --> 18:36.000] ‰ªÄÈ∫ºÂè´Ê≤íÊúâÁç≤Âà©ËÇ°Á•®‰Ω†Áúã6405ÁöÑ\n",
            "[18:36.000 --> 18:38.000] ÈÄôÂÄãË≤°Â†±\n",
            "[18:38.000 --> 18:40.000] Á¨¨‰∏ÄÂ≠£Ëôß0.09\n",
            "[18:40.000 --> 18:42.000] Á¨¨‰∫åÂ≠£Ëôß0.16\n",
            "[18:42.000 --> 18:44.000] Á¨¨‰∏âÂ≠£Êõ¥Âö¥Èáç\n",
            "[18:44.000 --> 18:46.000] Ëôß0.51\n",
            "[18:46.000 --> 18:48.000] ÈÇ£ÈÄôÂÄãËôßÊêç‰∏çÊòØÂ∞±ÊòØ\n",
            "[18:48.000 --> 18:50.000] Â§ßÊ¶ÇÊòØ‰∏ä‰∏ÄÂ≠£ÁöÑÂ•ΩÂπæ\n",
            "[18:50.000 --> 18:52.000] Â•ΩÂπæÂÄçÈÄôÊ®£Â≠ê\n",
            "[18:52.000 --> 18:54.000] ÈÇ£‰Ω†Ë™™‰ªñÂ∞±Ê≤íÊà≤‰∫Ü\n",
            "[18:54.000 --> 18:56.000] ÊúâÊ≤íÊúâÂèØËÉΩÂÜçÁπºÁ∫åÊº≤\n",
            "[18:56.000 --> 18:58.000] Áï∂ÁÑ∂ÊúâÊ©üÊúÉÁÇ∫‰ªÄÈ∫º\n",
            "[18:58.000 --> 19:00.000] ‰Ω†Áúã‰ªñË≥áÊú¨È°çÊâç6.58ÂÑÑ\n",
            "[19:00.000 --> 19:02.000] ÈÄôÁ®ÆÂ∞èËÇ°Êú¨ÁöÑ\n",
            "[19:02.000 --> 19:04.000] ËÇ°Á•®ÂÖ∂ÂØ¶\n",
            "[19:04.000 --> 19:06.000] ÈÄôÂÄãÁ±åÁ¢ºÂ∞±ÊéåÊè°Âú®ÂπæÂÄã‰∫∫Êâã‰∏ä\n",
            "[19:06.000 --> 19:08.000] Áï∂‰Ω†\n",
            "[19:08.000 --> 19:10.000] ÊéåÊè°Âú®ÂπæÂÄã‰∫∫Êâã‰∏äÁöÑÊôÇÂÄôÊòØÈÇ£‰∏Ä‰∫õ‰∫∫\n",
            "[19:10.000 --> 19:12.000] Ë™™ËëóÁÆó\n",
            "[19:12.000 --> 19:14.000] ÈÇ£Ëë£Áõ£ÊåÅËÇ°‰πüÊâçÂ§öÂ∞ë\n",
            "[19:14.000 --> 19:16.000] 8900Â§öÂºµ\n",
            "[19:16.000 --> 19:18.000] ÈÇ£ÁôºË°åÊòØ\n",
            "[19:18.000 --> 19:20.000] 65000Â§öÂºµ\n",
            "[19:20.000 --> 19:22.000] ÈÇ£ÈÄôÁ®ÆËÇ°ÂÉπÂèà‰∏çÈ´òÁöÑËÇ°Á•®\n",
            "[19:22.000 --> 19:24.000] ÂÖ∂ÂØ¶ÊúâÊñ∞‰∫∫\n",
            "[19:24.000 --> 19:26.000] ÊòØË¶Å‰æÜÊãâÊä¨\n",
            "[19:26.000 --> 19:28.000] ÁöÑÊôÇÂÄôÈÇÑÊòØÊúâÊ©üÊúÉ\n",
            "[19:28.000 --> 19:30.000] ÊâÄ‰ª•‰Ω†‰πü‰∏çË¶ÅÈö®‰æøÂéª\n",
            "[19:30.000 --> 19:32.000] ‰∫ÇÊîæÁ©∫\n",
            "[19:32.000 --> 19:34.000] ‰ΩÜÊòØ‰Ω†Ë¶ÅÂÅöÂà∞Â∞±ÊòØË™™\n",
            "[19:34.000 --> 19:36.000] ÈÄôÁ®ÆÂÖ¨Âè∏\n",
            "[19:36.000 --> 19:38.000] ‰∏çË¶ÅÁ¢∞Â∞±Âà•Á¢∞\n",
            "[19:38.000 --> 19:40.000] Âõ†ÁÇ∫‰Ω†\n",
            "[19:40.000 --> 19:42.000] Ë≤∑‰∏ÄÂÄãÊú™‰æÜ\n",
            "[19:42.000 --> 19:44.000] Èô§Èùû‰Ω†ÁúüÁöÑÂæà‰∫ÜËß£‰ªñ\n",
            "[19:44.000 --> 19:46.000] Áü•ÈÅìË™™ÈÄôÂÄãËÄÅÈóÜ\n",
            "[19:46.000 --> 19:48.000] ÊàñÊòØË™™ÈÄôÂÆ∂ÂÖ¨Âè∏\n",
            "[19:48.000 --> 19:50.000] ‰ªñÂà∞Â∫ïÊúâ‰ªÄÈ∫ºÂïÜÂìÅ\n",
            "[19:50.000 --> 19:52.000] ËÉΩÂ§†ËÆì‰ªñÊú™‰æÜ‰ºÅÊ•≠\n",
            "[19:52.000 --> 19:54.000] ÁπºÁ∫åÁöÑÁôºÂ±ï\n",
            "[19:54.000 --> 19:56.000] ‰Ω†ÊâçËÉΩÂ§†ÂéªË≤∑\n",
            "[19:56.000 --> 19:58.000] ÊâÄ‰ª•Êàë‰∏ÄÁõ¥Â∏∏Â∏∏Âú®Ë¨õË™™\n",
            "[19:58.000 --> 20:00.000] ‰∫íÊâøÂíå\n",
            "[20:00.000 --> 20:02.000] ÂÖ¨Âè∏ÁöÑ‰∫íÊâøÂíå\n",
            "[20:02.000 --> 20:04.000] Â∞±ÂÉèÊàë‰∏ä‰∏ÄÂÄãË≤°Â†±ÁöÑÊôÇÂÄô\n",
            "[20:04.000 --> 20:06.000] ‰ªñÊîæÊ£Ñ‰ªñÁ¢≥Â¢ûÂç°\n",
            "[20:06.000 --> 20:08.000] Á¢≥Â¢ûÂç°‰ªñÊòØÂèØ‰ª•Âà∞ÂÖ®ÁêÉ20%\n",
            "[20:08.000 --> 20:10.000] Êô∂Âúì‰ª£Â∑•ÁöÑ\n",
            "[20:10.000 --> 20:12.000] ÈÄôÂÄãÂè∞Á©çÈõª\n",
            "[20:12.000 --> 20:14.000] 3Â•àÁ±≥2Â•àÁ±≥1Â•àÁ±≥\n",
            "[20:14.000 --> 20:16.000] ÂÖ®ÁêÉÁ®±Èú∏\n",
            "[20:16.000 --> 20:18.000] ÈÄôÂÄãÂ∞±ÊòØ‰∫íÊâøÂíå\n",
            "[20:18.000 --> 20:20.000] ÈÇ£ÈÄôÁ®ÆÂÖ¨Âè∏Â∞±ÂÄºÂæó‰ªÄÈ∫º\n",
            "[20:20.000 --> 20:22.000] Â∞±ÂÄºÂæóÊìÅÊúâ\n",
            "[20:22.000 --> 20:24.000] ‰ΩÜÊòØ‰Ω†Ë™™ÈÄôÁ®ÆËôßÂ§ßÈå¢ÁöÑ\n",
            "[20:24.000 --> 20:26.000] ÂÖ¨Âè∏\n",
            "[20:26.000 --> 20:28.000] Áï∂ÁÑ∂‰Ω†ÊúÉÁî®ÈÇ£Á®Æ\n",
            "[20:28.000 --> 20:30.000] Âè≥ÂÅ¥‰∫§ÊòìÁöÑ\n",
            "[20:30.000 --> 20:32.000] ÊÄùËÄÉËßíÂ∫¶ÂéªÂÅöË≥≠Âçö\n",
            "[20:32.000 --> 20:34.000] ‰Ω†Ê≤íÊúâÂïèÈ°å\n",
            "[20:34.000 --> 20:36.000] ÊàëÊ≤íÊúâË¨õË™™\n",
            "[20:36.000 --> 20:38.000] ‰Ω†‰∏çËÉΩÂéªÂÅöÈÄôÁ®Æ‰∫ãÊÉÖ\n",
            "[20:38.000 --> 20:40.000] ÈÄôÁ®Æ‰∫ãÊÉÖÊòØÂèØ‰ª•ÂÅö\n",
            "[20:40.000 --> 20:42.000] ÂèØÊòØ‰Ω†Ë¶ÅÂÅöÂú®‰ªÄÈ∫º\n",
            "[20:42.000 --> 20:44.000] Ë¶ÅÂÅöÂú®ÈÇ£ÂÄãÈ†≠\n",
            "[20:44.000 --> 20:46.000] ÈÇ£ÂÄã‰∏ÉÂºµËáâ\n",
            "[20:46.000 --> 20:48.000] ÊØîÂ¶ÇË™™‰Ω†Ë™™\n",
            "[20:48.000 --> 20:50.000] ÊàëÂÄëÂ∞±ÁúãÈÄôÂÄãËôßÊêçÂÖ¨Âè∏ÊúàÊàê\n",
            "[20:50.000 --> 20:52.000] 6405ÁöÑÈÄôÂÄã\n",
            "[20:52.000 --> 20:54.000] Ëµ∞Âã¢Âúñ\n",
            "[20:54.000 --> 20:56.000] ‰Ω†Áúã8Êúà21ÁöÑÊôÇÂÄô70Âºµ\n",
            "[20:56.000 --> 20:58.000] ‰πãÂâçÂ§ßÊ¶ÇÈÉΩÂú®\n",
            "[20:58.000 --> 21:00.000] ‰∏ÄÂÖ©ÁôæÂºµ\n",
            "[21:00.000 --> 21:02.000] 8Êúà22ÁöÑÊôÇÂÄôÂà∞884Âºµ\n",
            "[21:02.000 --> 21:04.000] ÈÄôÂÄãÂ∞±‰æõÁµ¶Èáè\n",
            "[21:04.000 --> 21:06.000] ÈÇ£‰Ω†‰∏ÄÂÆöÊòØÁúã‰∏çÂà∞\n",
            "[21:06.000 --> 21:08.000] Ë≤°Â†±ÁöÑ\n",
            "[21:08.000 --> 21:10.000] ÊâÄ‰ª•‰Ω†Âè™ËÉΩË≤∑Âú®‰æõÁµ¶Èáè\n",
            "[21:10.000 --> 21:12.000] Áî®Ë≥≠ÁöÑÊñπÂºèÂéªË≥≠\n",
            "[21:12.000 --> 21:14.000] ÂèØÊòØ‰Ω†Ë≥£Âá∫‰∏âËó•ÂäçÂá∫‰æÜ\n",
            "[21:14.000 --> 21:16.000] Âú®9Êúà6ËôüÁöÑÊôÇÂÄô43197Âºµ\n",
            "[21:16.000 --> 21:18.000] ÈÇ£‰Ω†Â∞±Áü•ÈÅì\n",
            "[21:18.000 --> 21:20.000] Â∞§ÂÖ∂ÂèàË∑åÁ†¥‰∫îÊó•Á∑ö\n",
            "[21:20.000 --> 21:22.000] ÈÇ£‰Ω†Â∞±Áü•ÈÅì‰Ω†Ë¶ÅÂá∫\n",
            "[21:22.000 --> 21:24.000] Âá∫ÈÇ£‰Ω†Ë™™\n",
            "[21:24.000 --> 21:26.000] ‰Ω†ÂèàË≤∑Âõû‰æÜÂèàË¶ÅÈÄôÊ®£ÁπºÁ∫åÂÅö\n",
            "[21:26.000 --> 21:28.000] ‰Ω†Ë¶∫Âæó‰Ω†ÊúâÂèØËÉΩÂóé\n",
            "[21:28.000 --> 21:30.000] ÂÅö‰∏çÂà∞ÁöÑ\n",
            "[21:30.000 --> 21:32.000] ÊâÄ‰ª•Êàë\n",
            "[21:32.000 --> 21:34.000] Âü∫Êú¨‰∏ä‰∏çÊúÉÂéªPO\n",
            "[21:34.000 --> 21:36.000] ÊâÄ‰ª•ÊàëÂÄë‰ªäÂ§©Ë¶ÅË´áÁöÑ\n",
            "[21:36.000 --> 21:38.000] Â∞±ÊòØÂ≠óÁØÄ\n",
            "[21:38.000 --> 21:40.000] Â≠óÁØÄÂ∞çÂ•ΩÁöÑËÇ°Á•®\n",
            "[21:40.000 --> 21:42.000] ÂÆÉÊúâÂä†ÂàÜÁöÑ‰ΩúÁî®\n",
            "[21:42.000 --> 21:44.000] Â∞±ÂÉèÊàëÂâõÂâõÂâçÈù¢Ë¨õÁöÑËÉéËä±\n",
            "[21:44.000 --> 21:46.000] ÂÆÉÂèØËÉΩÂèØ‰ª•ËÆì‰Ω†\n",
            "[21:46.000 --> 21:48.000] ÈÄôÂÄãÊº≤‰∫ÜÂèØËÉΩÂ∑≤Á∂ìÊòØ\n",
            "[21:48.000 --> 21:50.000] ‰∫îÊ†π‰∫ÜÂÖ≠Ê†π‰∫Ü\n",
            "[21:50.000 --> 21:52.000] ÁÑ∂Âæå‰∏ÄÂÄãÂÖ¨‰ΩàÂÆÉÂèØ‰ª•ÂÜçÊº≤‰∏ÉÊ†πÂÖ´Ê†π\n",
            "[21:52.000 --> 21:54.000] Êº≤Âà∞ÂçÅÊ†πÈÉΩÊúâÂèØËÉΩ\n",
            "[21:54.000 --> 21:56.000] ‰ΩÜÊòØÂÆÉ‰πüÊúâÂèØËÉΩËÆì‰ªÄÈ∫º\n",
            "[21:56.000 --> 21:58.000] ÈÄôÁ®ÆËÖ∞È™®‰∏ÄÂ§ï‰πãÈñìÂ∞±\n",
            "[21:58.000 --> 22:00.000] Â§¢ÈÜíÂçÅÂàÜ\n",
            "[22:00.000 --> 22:02.000] Â§¢ÈÜíÂçÅÂàÜ\n",
            "[22:02.000 --> 22:04.000] ÁÑ∂ÂæåÂë¢\n",
            "[22:04.000 --> 22:06.000] ÊääÂÆÉ‰∏ÄÂÄãÊâìËáâ‰∏ãÂéª\n",
            "[22:06.000 --> 22:08.000] Áï∂‰∏ªÂäõ‰ªñÁúüÁöÑ\n",
            "[22:08.000 --> 22:10.000] ‰∏ÄÂøÉÊÉ≥Ë¶ÅÂÅöÁöÑÊôÇÂÄô\n",
            "[22:10.000 --> 22:12.000] ‰ªñ‰∏çÊòØ\n",
            "[22:12.000 --> 22:14.000] ‰ªñ‰∏çÁÆ°‰Ω†ÈÄô‰∫õÂ≠óÁØÄÁöÑ\n",
            "[22:14.000 --> 22:16.000] ‰ªñÊòØÊéßÂà∂Á±åÁ¢ºÁöÑ\n",
            "[22:16.000 --> 22:18.000] ÊàëÂÄëË¨õËÇ°Á•®ÁöÑÊº≤ÈªûÂ∞±ÊòØ‰æõÈúÄ\n",
            "[22:18.000 --> 22:20.000] ‰æõÁµ¶ÈúÄÊ±Ç\n",
            "[22:20.000 --> 22:22.000] ËÄå‰∏çÊòØË™™\n",
            "[22:22.000 --> 22:24.000] Ë∑üÈÄôÂÄã\n",
            "[22:24.000 --> 22:26.000] ÈÄôÂÄãË≤°Â†±Êúâ‰∏ÄÂÆöÁöÑÈóú‰øÇ\n",
            "[22:26.000 --> 22:28.000] ÊúÄÂæåÊúÄÂæå\n",
            "[22:28.000 --> 22:30.000] ÂèØËÉΩ‰∫îÂÄãÊúà\n",
            "[22:30.000 --> 22:32.000] ÂçÅÂÄãÊúàÊàñÊòØ‰∏ÄÂπ¥ÂÖ©Âπ¥Âæå\n",
            "[22:32.000 --> 22:34.000] ÂÆÉÂèØËÉΩÊúÉË∑üË≤°Â†±ÊúâÈóú‰øÇ\n",
            "[22:34.000 --> 22:36.000] ‰ΩÜÊòØÂÆÉ\n",
            "[22:36.000 --> 22:38.000] Áï∂‰∏ãÊàñÊòØÊòéÂ§©ÊàñÊòØ\n",
            "[22:38.000 --> 22:40.000] ‰∏ãÂÄãÁ¶ÆÊãúÂèØËÉΩË∑ü\n",
            "[22:40.000 --> 22:42.000] ÈÄôÂÄãË≥áÈáë\n",
            "[22:42.000 --> 22:44.000] ÊàëÂÄëË¨õÁöÑÂ∞±ÊòØË≥áÈáëÈù¢\n",
            "[22:44.000 --> 22:46.000] ÈÇÑÊúâÈÄôÂÄãÊï¥ÂÄã\n",
            "[22:46.000 --> 22:48.000] ÁÜ±Â∫¶\n",
            "[22:48.000 --> 22:50.000] ÂæàÂ§öÁöÑÊîØÁ∑öÊΩÆÁöÑË©±È°å\n",
            "[22:50.000 --> 22:52.000] Ê©üÂô®‰∫∫\n",
            "[22:52.000 --> 22:54.000] ÈÄôÂÄã‰ªÄÈ∫º\n",
            "[22:54.000 --> 22:56.000] Âê∏ÂÖâÂ≠ê\n",
            "[22:56.000 --> 22:58.000] ÂÖâÁ¥∞Â≠ê\n",
            "[22:58.000 --> 23:00.000] Èô§ËÉΩ\n",
            "[23:00.000 --> 23:02.000] ÈÄô‰∫õÂèØËÉΩÊúâÈóú‰øÇ\n",
            "[23:02.000 --> 23:04.000] ÁÜ±Â∫¶ÁöÑÈóú‰øÇ\n",
            "[23:04.000 --> 23:06.000] ‰ΩÜÊòØÂë¢\n",
            "[23:06.000 --> 23:08.000] ÊúÄÂæåÈÇÑÊòØË¶ÅÂèçÊáâÂú®\n",
            "[23:08.000 --> 23:10.000] Ê•≠Á∏æ‰∏äÈù¢\n",
            "[23:10.000 --> 23:12.000] ÈÇ£Êó¢ÁÑ∂‰Ω†ÈÄôÂÄãÊù±Ë•øÊä±‰∏ç‰Ωè‰Ω†Â∞±Âà•Êä±\n",
            "[23:12.000 --> 23:14.000] ÊâÄ‰ª•\n",
            "[23:14.000 --> 23:16.000] ÊàëÂú®ÂÅö‰ªäÂ§©ÁöÑ‰∏ÄÂÄãÁ∏ΩÊï¥ÁêÜ\n",
            "[23:16.000 --> 23:18.000] Â∞±ÊòØË™™\n",
            "[23:18.000 --> 23:20.000] Â¶ÇÊûú‰ªñÁöÑÈÄôÂÄã\n",
            "[23:20.000 --> 23:22.000] ÊòØÊúâÂü∫Êú¨Èù¢ÁöÑ\n",
            "[23:22.000 --> 23:24.000] ÈÇ£‰ªñÂÖ¨‰ΩàËá™Ëß£ÁöÑÊôÇÂÄôÂ¶ÇÊûúÊòØÂ•ΩÁöÑË©±\n",
            "[23:24.000 --> 23:26.000] ‰ªñÂèØËÉΩÊúÉÊõ¥‰∏ä‰∏ÄÂ±§Ê®ì\n",
            "[23:26.000 --> 23:28.000] ÈÄôÂÄãÊàëÂÄëË¨õÁöÑÊòØ‰∏ÄËà¨\n",
            "[23:28.000 --> 23:30.000] ÈÇèËºØ\n",
            "[23:30.000 --> 23:32.000] Áï∂ÁÑ∂Êúâ‰∏Ä‰∫õÁâπ‰æã\n",
            "[23:32.000 --> 23:34.000] ÊâÄ‰ª•ÊàëË™™‰Ω†Ë¶ÅÂ§öÂ±§Ê¨°\n",
            "[23:34.000 --> 23:36.000] Â§öÂ±§Ê¨°ÁöÑÊÄùËÄÉ\n",
            "[23:36.000 --> 23:38.000] ÈÇ£Â¶ÇÊûú‰ªñÁöÑÈÄôÂÄãË≤°Â†±\n",
            "[23:38.000 --> 23:40.000] ‰∏çÊòØÂæàÂ•ΩÂ∞±ÊòØÁî®ËôßÊêç\n",
            "[23:40.000 --> 23:42.000] ÂÖ¨Âè∏ÁÑ∂Âæå‰∏ÄÁõ¥È£ÜÁöÑÈÇ£Á®Æ\n",
            "[23:42.000 --> 23:44.000] ÈÇ£ÂÖ¨‰ΩàÁöÑÊôÇÂÄôÂèØËÉΩÊúÉÊää‰ªñÊâìËáâ\n",
            "[23:44.000 --> 23:46.000] ÈÄôÂÄã‰πüÊòØ‰∏ÄËà¨ÊÉÖÊ≥Å\n",
            "[23:46.000 --> 23:48.000] Áï∂ÁÑ∂‰∏ªÂäõË¶ÅÂÅö‰ªñÈÇÑÊòØÊúÉ\n",
            "[23:48.000 --> 23:50.000] ÈÇÑÊòØÊúÉÁπºÁ∫åÊº≤\n",
            "[23:50.000 --> 23:52.000] ÊâÄ‰ª•ÊàëÂÄã‰∫∫Ë™çÁÇ∫\n",
            "[23:52.000 --> 23:54.000] ÈÄôÁ®Æ\n",
            "[23:54.000 --> 23:56.000] Â¶ÇÊûúÊúâË©±È°å‰ΩÜÊòØÂü∫Êú¨Èù¢\n",
            "[23:56.000 --> 23:58.000] Ê≤íÊúâÁúãÂà∞Â•ΩËΩâÁöÑÂÖ¨Âè∏Êàë‰∏çÂª∫Ë≠∞Á¢∞\n",
            "[23:58.000 --> 24:00.000] Êàë‰∏çÂª∫Ë≠∞Á¢∞ÊàëÂÄã‰∫∫\n",
            "[24:00.000 --> 24:02.000] Âú®ÊäïË≥áÁîüÊ∂ØË£°Èù¢\n",
            "[24:02.000 --> 24:04.000] ÂæàÂ∞ëÁ¢∞ÈÄôÁ®Æ\n",
            "[24:04.000 --> 24:06.000] ÈÄô‰∏ÄÈ°ûÁöÑËÇ°Á•®Â∞§ÂÖ∂ÈÄôÁ®Æ\n",
            "[24:06.000 --> 24:08.000] ÊàëÂ∞±ÊòØÊòéÁü•ÈÅì‰ªñÊòØ\n",
            "[24:08.000 --> 24:10.000] ÁÇí‰ΩúÁöÑÂÖ¨Âè∏ÈÇ£ÊàëÁ°¨Ë¶ÅÂéª\n",
            "[24:10.000 --> 24:12.000] Ë∑ü‰∫∫ÂÆ∂\n",
            "[24:12.000 --> 24:14.000] ÈÄôÂÄãÊàëÂèà‰∏çÊòØ‰∏ªÂäõ\n",
            "[24:14.000 --> 24:16.000] Â∞ç‰∏çÂ∞çÁ°¨Ë¶ÅË∑ü‰∫∫ÂÆ∂ÂéªÊØî\n",
            "[24:16.000 --> 24:18.000] Âà∞Â∫ïËÉΩ‰∏çËÉΩË≥£Âú®ÊúÄÈ´òÈªû\n",
            "[24:18.000 --> 24:20.000] ÈÄô‰∫õÈÇ£ÊàëË™çÁÇ∫\n",
            "[24:20.000 --> 24:22.000] ‰∏çÂÆπÊòì\n",
            "[24:22.000 --> 24:24.000] ÈÇ£‰Ω†‰∏ÄÈñãÂßãÂ∞±Âà•Á¢∞\n",
            "[24:24.000 --> 24:26.000] ÊâÄ‰ª•\n",
            "[24:26.000 --> 24:28.000] ÂêÑ‰ΩçÂú®ÂÅöËÇ°Á•®ÁöÑÊôÇÂÄôË¶ÅÂéªÊ≥®ÊÑè\n",
            "[24:28.000 --> 24:30.000] ÈÄô‰∫õ\n",
            "[24:30.000 --> 24:32.000] ËôßÊêçÂÖ¨Âè∏ÁöÑÂïèÈ°å\n",
            "[24:32.000 --> 24:34.000] ÈÇ£ÁèæÂú®‰æÜË¨õÂ∞±ÊòØ\n",
            "[24:34.000 --> 24:36.000] ‰Ω†Ë¶ÅÂÖàÂéªÊ≥®ÊÑèË™™Âì™‰∏Ä‰∫õ\n",
            "[24:36.000 --> 24:38.000] ËÇ°Á•®ËÆäÊ≥®ÊÑèËÇ°\n",
            "[24:38.000 --> 24:40.000] Áï∂ÁÑ∂Ê≥®ÊÑèËÇ°‰ªñÁöÑÈÄôÂÄã\n",
            "[24:40.000 --> 24:42.000] Ë¶èÂÆö‰πüÂæàÂ§ö\n",
            "[24:42.000 --> 24:44.000] Âë®ËΩâÁéáÊúâ‰ªÄÈ∫º\n",
            "[24:44.000 --> 24:46.000] ÂπÖÂ∫¶ÂïäÊº≤ÂπÖÂïäË∑åÂπÖÂïä\n",
            "[24:46.000 --> 24:48.000] Á≠âÁ≠âÈÄô‰∫õ‰Ω†ÂèØ‰ª•Âéª\n",
            "[24:48.000 --> 24:50.000] ÈÄôÂÄã\n",
            "[24:50.000 --> 24:52.000] ‰∫§ÊòìÊâÄÁöÑÈÄôÂÄãÁ∂≤Á´ôÂéªÁúã\n",
            "[24:52.000 --> 24:54.000] ÊàñËÄÖÊòØGoogleÊü•‰∏Ä‰∏ãÂ∞±Êü•ÂæóÂà∞\n",
            "[24:54.000 --> 24:56.000] ÁÑ∂ÂæåÂë¢‰ªñÈÄôÂÄãÊ≥®ÊÑèËÇ°ÁöÑÊôÇÂÄô\n",
            "[24:56.000 --> 24:58.000] ‰ªñÂèØËÉΩÊúÉÂè´‰Ω†ÂÖ¨‰ΩàÂ≠óÁØÄ\n",
            "[24:58.000 --> 25:00.000] ÈÇ£‰Ω†Â∞±ÁúãÂ≠óÁØÄ\n",
            "[25:00.000 --> 25:02.000] Âà∞Â∫ïÊòØÊúâÊ≤íÊúâÂÜçÂ¢ûÂä†\n",
            "[25:02.000 --> 25:04.000] Â¶ÇÊûúÂÜçÂ¢ûÂä†ÈÄôËÇ°Â∏ÇÂèØËÉΩÊúÉ\n",
            "[25:04.000 --> 25:06.000] ÁπºÁ∫åË∂äÁáíË∂äÊó∫\n",
            "[25:06.000 --> 25:08.000] Âõ†ÁÇ∫ÈÄöÂ∏∏ÈÄôÁ®ÆËÇ°Á•®ÈÉΩÊòØÂ∑≤Á∂ìÊº≤ÂæàÂ§öÁöÑ\n",
            "[25:08.000 --> 25:10.000] ÊâçÊúÉÂéªÂÖ¨‰ΩàË∂äÁáíË∂äÊó∫\n",
            "[25:10.000 --> 25:12.000] ÈÇ£Â¶ÇÊûúÁúüÁöÑ\n",
            "[25:12.000 --> 25:14.000] ÊòØÈù†Âü∫Êú¨Èù¢ÁöÑÊôÇÂÄôÈÄôÂÄãÂ≠óÁØÄ\n",
            "[25:14.000 --> 25:16.000] Á™ÅÁÑ∂Âá∫Áèæ‰∏çÊòØÂæàÂ•ΩÁöÑÊôÇÂÄô\n",
            "[25:16.000 --> 25:18.000] ÊàëÊòØÂª∫Ë≠∞‰Ω†Ë≥£Êéâ\n",
            "[25:18.000 --> 25:20.000] ÈÇ£Â¶ÇÊûúÊòØËÖ∞È™®ÁöÑË©±\n",
            "[25:20.000 --> 25:22.000] ‰ªñÂá∫ÁèæÈÄôÂÄã\n",
            "[25:22.000 --> 25:24.000] Â≠óÁØÄ‰∏çÂ•ΩÁöÑÊôÇÂÄô\n",
            "[25:24.000 --> 25:26.000] Êàë‰πüÊòØÂª∫Ë≠∞\n",
            "[25:26.000 --> 25:28.000] ‰Ω†Â∞±ÂÖàË≥£ÊéâÂõûÂÆ∂Âï¶\n",
            "[25:28.000 --> 25:30.000] ÈÇ£ÈÄôÂÄãÂ¶ÇÊûú‰ªñÊòØ\n",
            "[25:30.000 --> 25:32.000] ËÖ∞È™®‰ΩÜÊòØ‰ªñÈÄôÂÄãÂ≠óÁØÄ\n",
            "[25:32.000 --> 25:34.000] ‰∏çÈåØÁöÑË©±\n",
            "[25:34.000 --> 25:36.000] ÈÇ£Â∞±Ê≥®ÊÑèÂõâÈÇ£‰Ω†ÂèØËÉΩÈÇÑÂèØ‰ª•ÁπºÁ∫å‰øù\n",
            "[25:36.000 --> 25:38.000] ÈÇÑÂèØ‰ª•ÁπºÁ∫å‰øù\n",
            "[25:38.000 --> 25:40.000] ÈÇ£ÈÄôÂÄãÊòØ‰∏ÄÂÄãÊØîËºÉ\n",
            "[25:40.000 --> 25:42.000] ÁâáÈù¢ÊàëË¨õÁúüÁöÑÊòØÊØîËºÉÁâáÈù¢\n",
            "[25:42.000 --> 25:44.000] ‰πü‰∏çÊúÉÂÆåÂÖ®Â∞±ÁÖßÊàëÈÄôÂÄãË¨õÊ≥ï\n",
            "[25:44.000 --> 25:46.000] ÂéªËµ∞ÈÄôÂÄãÈÇÑÊúâÂæàÂ§öÂ§öÂ±§Ê¨°\n",
            "[25:46.000 --> 25:48.000] ÁöÑÊÄùËÄÉÂ§öËßíÂ∫¶ÁöÑ‰∏ÄÂÄãËßÄÂØü\n",
            "[25:48.000 --> 25:50.000] Â•ΩÈÇ£‰ªäÂ§©Á°¨ÊâìÂà∞ÈÄôÈÇä\n",
            "[25:50.000 --> 25:52.000] ÈÄôÂÄãÂØÜÁ¢ºÊòØ\n",
            "[25:52.000 --> 25:54.000] 2522\n",
            "[25:54.000 --> 25:56.000] Á•ùÁ¶èÂ§ßÂÆ∂ÊúâÂÄãÁæéÂ•ΩÁöÑ‰∏ÄÊôöÊôö\n"
          ]
        }
      ],
      "source": [
        "import os, subprocess\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import format_timestamp, get_writer, WriteTXT\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
        "except ImportError:\n",
        "  pass\n",
        "\n",
        "import torch\n",
        "\n",
        "import math\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# select task\n",
        "\n",
        "task = \"Transcribe\" #@param [\"Transcribe\", \"Translate to English\"]\n",
        "\n",
        "task = \"transcribe\" if task == \"Transcribe\" else \"translate\"\n",
        "\n",
        "# select audio file\n",
        "\n",
        "audio_file = \"/content/12-10Ë´áËá™Áµê.m4a\" #@param {type:\"string\"}\n",
        "\n",
        "audio_files = list(map(lambda audio_path: audio_path.strip(), audio_file.split(',')))\n",
        "\n",
        "for audio_path in audio_files:\n",
        "  if not os.path.isfile(audio_path):\n",
        "    raise FileNotFoundError(audio_path)\n",
        "\n",
        "# set model\n",
        "\n",
        "use_model = \"medium\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v1\", \"large-v2\"]\n",
        "\n",
        "# select language\n",
        "\n",
        "language = \"Chinese\" #@param [\"Auto-Detect\", \"Afrikaans\", \"Albanian\", \"Amharic\", \"Arabic\", \"Armenian\", \"Assamese\", \"Azerbaijani\", \"Bashkir\", \"Basque\", \"Belarusian\", \"Bengali\", \"Bosnian\", \"Breton\", \"Bulgarian\", \"Burmese\", \"Castilian\", \"Catalan\", \"Chinese\", \"Croatian\", \"Czech\", \"Danish\", \"Dutch\", \"English\", \"Estonian\", \"Faroese\", \"Finnish\", \"Flemish\", \"French\", \"Galician\", \"Georgian\", \"German\", \"Greek\", \"Gujarati\", \"Haitian\", \"Haitian Creole\", \"Hausa\", \"Hawaiian\", \"Hebrew\", \"Hindi\", \"Hungarian\", \"Icelandic\", \"Indonesian\", \"Italian\", \"Japanese\", \"Javanese\", \"Kannada\", \"Kazakh\", \"Khmer\", \"Korean\", \"Lao\", \"Latin\", \"Latvian\", \"Letzeburgesch\", \"Lingala\", \"Lithuanian\", \"Luxembourgish\", \"Macedonian\", \"Malagasy\", \"Malay\", \"Malayalam\", \"Maltese\", \"Maori\", \"Marathi\", \"Moldavian\", \"Moldovan\", \"Mongolian\", \"Myanmar\", \"Nepali\", \"Norwegian\", \"Nynorsk\", \"Occitan\", \"Panjabi\", \"Pashto\", \"Persian\", \"Polish\", \"Portuguese\", \"Punjabi\", \"Pushto\", \"Romanian\", \"Russian\", \"Sanskrit\", \"Serbian\", \"Shona\", \"Sindhi\", \"Sinhala\", \"Sinhalese\", \"Slovak\", \"Slovenian\", \"Somali\", \"Spanish\", \"Sundanese\", \"Swahili\", \"Swedish\", \"Tagalog\", \"Tajik\", \"Tamil\", \"Tatar\", \"Telugu\", \"Thai\", \"Tibetan\", \"Turkish\", \"Turkmen\", \"Ukrainian\", \"Urdu\", \"Uzbek\", \"Valencian\", \"Vietnamese\", \"Welsh\", \"Yiddish\", \"Yoruba\"]\n",
        "\n",
        "# other parameters\n",
        "\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "\n",
        "coherence_preference = \"More coherence, but may repeat text\" #@param [\"More coherence, but may repeat text\", \"Less repetitions, but may have less coherence\"]\n",
        "\n",
        "api_key = '' #@param {type:\"string\"}\n",
        "\n",
        "# detect device\n",
        "\n",
        "if api_key:\n",
        "  print(\"Using API\")\n",
        "\n",
        "  from pydub import AudioSegment\n",
        "  from pydub.silence import split_on_silence\n",
        "else:\n",
        "  DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "  print(f\"Using {'GPU' if DEVICE == 'cuda' else 'CPU ‚ö†Ô∏è'}\")\n",
        "\n",
        "  # https://medium.com/analytics-vidhya/the-google-colab-system-specification-check-69d159597417\n",
        "  if DEVICE == \"cuda\":\n",
        "    !nvidia-smi -L\n",
        "  else:\n",
        "    if sys_platform == 'linux':\n",
        "      !lscpu | grep \"Model name\" | awk '{$1=$1};1'\n",
        "\n",
        "    print(\"Not using GPU can result in a very slow execution\")\n",
        "    print(\"Ensure Hardware accelerator by GPU is enabled in Google Colab: Runtime > Change runtime type\")\n",
        "\n",
        "    if use_model not in ['tiny', 'base', 'small']:\n",
        "      print(\"You may also want to try a smaller model (tiny, base, small)\")\n",
        "\n",
        "# display language\n",
        "\n",
        "WHISPER_LANGUAGES = [k.title() for k in whisper.tokenizer.TO_LANGUAGE_CODE.keys()]\n",
        "\n",
        "if language == \"Auto-Detect\":\n",
        "  language = \"detect\"\n",
        "\n",
        "if language and language != \"detect\" and language not in WHISPER_LANGUAGES:\n",
        "  print(f\"\\nLanguage '{language}' is invalid\")\n",
        "  language = \"detect\"\n",
        "\n",
        "if language and language != \"detect\":\n",
        "  print(f\"\\nLanguage: {language}\")\n",
        "\n",
        "# load model\n",
        "\n",
        "if api_key:\n",
        "  print()\n",
        "else:\n",
        "  MODELS_WITH_ENGLISH_VERSION = [\"tiny\", \"base\", \"small\", \"medium\"]\n",
        "\n",
        "  if language == \"English\" and use_model in MODELS_WITH_ENGLISH_VERSION:\n",
        "    use_model += \".en\"\n",
        "\n",
        "  print(f\"\\nLoading {use_model} model... {os.path.expanduser(f'~/.cache/whisper/{use_model}.pt')}\")\n",
        "\n",
        "  model = whisper.load_model(use_model, device=DEVICE)\n",
        "\n",
        "  print(\n",
        "      f\"Model {use_model} is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "      f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,d} parameters.\\n\"\n",
        "  )\n",
        "\n",
        "# set options\n",
        "\n",
        "## https://github.com/openai/whisper/blob/v20231117/whisper/transcribe.py#L37\n",
        "## https://github.com/openai/whisper/blob/v20231117/whisper/decoding.py#L81\n",
        "options = {\n",
        "    'task': task,\n",
        "    'verbose': True,\n",
        "    'fp16': True,\n",
        "    'best_of': 5,\n",
        "    'beam_size': 5,\n",
        "    'patience': None,\n",
        "    'length_penalty': None,\n",
        "    'suppress_tokens': '-1',\n",
        "    'temperature': (0.0, 0.2, 0.4, 0.6, 0.8, 1.0), # float or tuple\n",
        "    'condition_on_previous_text': coherence_preference == \"More coherence, but may repeat text\",\n",
        "    'initial_prompt': prompt or None,\n",
        "    'word_timestamps': False,\n",
        "}\n",
        "\n",
        "if api_key:\n",
        "  api_client = OpenAI(api_key=api_key)\n",
        "\n",
        "  api_supported_formats = ['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'webm']\n",
        "  api_max_bytes = 25 * 1024 * 1024 # 25 MB\n",
        "\n",
        "  api_transcribe = api_client.audio.transcriptions if task == 'transcribe' else api_client.audio.translations\n",
        "  api_transcribe = api_transcribe.create\n",
        "\n",
        "  api_model = 'whisper-1' # large-v2\n",
        "\n",
        "  # https://platform.openai.com/docs/api-reference/audio?lang=python\n",
        "  api_options = {\n",
        "    'response_format': 'verbose_json',\n",
        "  }\n",
        "\n",
        "  if prompt:\n",
        "    api_options['prompt'] = prompt\n",
        "\n",
        "  api_temperature = options['temperature'][0] if isinstance(options['temperature'], (tuple, list)) else options['temperature']\n",
        "\n",
        "  if isinstance(api_temperature, (float, int)):\n",
        "    api_options['temperature'] = api_temperature\n",
        "  else:\n",
        "    raise ValueError(\"Invalid temperature type, it must be a float or a tuple of floats\")\n",
        "elif DEVICE == 'cpu':\n",
        "  options['fp16'] = False\n",
        "  torch.set_num_threads(os.cpu_count())\n",
        "\n",
        "# execute task\n",
        "# !whisper \"{audio_file}\" --task {task} --model {use_model} --output_dir {output_dir} --device {DEVICE} --verbose {options['verbose']}\n",
        "\n",
        "if task == \"translate\":\n",
        "  print(\"-- TRANSLATE TO ENGLISH --\")\n",
        "else:\n",
        "  print(\"-- TRANSCRIPTION --\")\n",
        "\n",
        "results = {} # audio_path to result\n",
        "\n",
        "for audio_path in audio_files:\n",
        "  print(f\"\\nProcessing: {audio_path}\\n\")\n",
        "\n",
        "  # detect language\n",
        "  detect_language = not language or language == \"detect\"\n",
        "\n",
        "  if not detect_language:\n",
        "    options['language'] = language\n",
        "    source_language_code = whisper.tokenizer.TO_LANGUAGE_CODE.get(language.lower())\n",
        "  elif not api_key:\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio_path)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "\n",
        "    source_language_code = max(probs, key=probs.get)\n",
        "    options['language'] = whisper.tokenizer.LANGUAGES[source_language_code].title()\n",
        "\n",
        "    print(f\"Detected language: {options['language']}\\n\")\n",
        "\n",
        "  # transcribe\n",
        "  if api_key:\n",
        "    # API\n",
        "    if task == \"transcribe\" and not detect_language:\n",
        "      api_options['language'] = source_language_code\n",
        "\n",
        "    source_audio_name_path, source_audio_ext = os.path.splitext(audio_path)\n",
        "    source_audio_ext = source_audio_ext[1:]\n",
        "\n",
        "    if source_audio_ext in api_supported_formats:\n",
        "      api_audio_path = audio_path\n",
        "      api_audio_ext = source_audio_ext\n",
        "    else:\n",
        "      ## convert audio file to a supported format\n",
        "      if options['verbose']:\n",
        "        print(f\"API supported formats: {','.join(api_supported_formats)}\")\n",
        "        print(f\"Converting {source_audio_ext} audio to a supported format...\")\n",
        "\n",
        "      api_audio_ext = 'mp3'\n",
        "\n",
        "      api_audio_path = f'{source_audio_name_path}.{api_audio_ext}'\n",
        "\n",
        "      subprocess.run(['ffmpeg', '-i', audio_path, api_audio_path], check=True, capture_output=True)\n",
        "\n",
        "      if options['verbose']:\n",
        "        print(api_audio_path, end='\\n\\n')\n",
        "\n",
        "    ## split audio file in chunks\n",
        "    api_audio_chunks = []\n",
        "\n",
        "    audio_bytes = os.path.getsize(api_audio_path)\n",
        "\n",
        "    if audio_bytes >= api_max_bytes:\n",
        "      if options['verbose']:\n",
        "        print(f\"Audio exceeds API maximum allowed file size.\\nSplitting audio in chunks...\")\n",
        "\n",
        "      audio_segment_file = AudioSegment.from_file(api_audio_path, api_audio_ext)\n",
        "\n",
        "      min_chunks = math.ceil(audio_bytes / (api_max_bytes / 2))\n",
        "\n",
        "      # print(f\"Min chunks: {min_chunks}\")\n",
        "\n",
        "      max_chunk_milliseconds = int(len(audio_segment_file) // min_chunks)\n",
        "\n",
        "      # print(f\"Max chunk milliseconds: {max_chunk_milliseconds}\")\n",
        "\n",
        "      def add_chunk(api_audio_chunk):\n",
        "        api_audio_chunk_path = f\"{source_audio_name_path}_{len(api_audio_chunks) + 1}.{api_audio_ext}\"\n",
        "        api_audio_chunk.export(api_audio_chunk_path, format=api_audio_ext)\n",
        "        api_audio_chunks.append(api_audio_chunk_path)\n",
        "\n",
        "      def raw_split(big_chunk):\n",
        "        subchunks = math.ceil(len(big_chunk) / max_chunk_milliseconds)\n",
        "\n",
        "        for subchunk_i in range(subchunks):\n",
        "          chunk_start = max_chunk_milliseconds * subchunk_i\n",
        "          chunk_end = min(max_chunk_milliseconds * (subchunk_i + 1), len(big_chunk))\n",
        "          add_chunk(big_chunk[chunk_start:chunk_end])\n",
        "\n",
        "      non_silent_chunks = split_on_silence(audio_segment_file,\n",
        "                                           seek_step=5, # ms\n",
        "                                           min_silence_len=1250, # ms\n",
        "                                           silence_thresh=-25, # dB\n",
        "                                           keep_silence=True) # needed to aggregate timestamps\n",
        "\n",
        "      # print(f\"Non silent chunks: {len(non_silent_chunks)}\")\n",
        "\n",
        "      current_chunk = non_silent_chunks[0] if non_silent_chunks else audio_segment_file\n",
        "\n",
        "      for next_chunk in non_silent_chunks[1:]:\n",
        "        if len(current_chunk) > max_chunk_milliseconds:\n",
        "          raw_split(current_chunk)\n",
        "          current_chunk = next_chunk\n",
        "        elif len(current_chunk) + len(next_chunk) <= max_chunk_milliseconds:\n",
        "          current_chunk += next_chunk\n",
        "        else:\n",
        "          add_chunk(current_chunk)\n",
        "          current_chunk = next_chunk\n",
        "\n",
        "      if len(current_chunk) > max_chunk_milliseconds:\n",
        "        raw_split(current_chunk)\n",
        "      else:\n",
        "        add_chunk(current_chunk)\n",
        "\n",
        "      if options['verbose']:\n",
        "        print(f'Total chunks: {len(api_audio_chunks)}\\n')\n",
        "    else:\n",
        "      api_audio_chunks.append(api_audio_path)\n",
        "\n",
        "    ## process chunks\n",
        "    result = None\n",
        "\n",
        "    for api_audio_chunk_path in api_audio_chunks:\n",
        "      ## API request\n",
        "      with open(api_audio_chunk_path, 'rb') as api_audio_file:\n",
        "        api_result = api_transcribe(model=api_model, file=api_audio_file, **api_options)\n",
        "        api_result = api_result.model_dump() # to dict\n",
        "\n",
        "      api_segments = api_result['segments']\n",
        "\n",
        "      if result:\n",
        "        ## update timestamps\n",
        "        last_segment_timestamp = result['segments'][-1]['end'] if result['segments'] else 0\n",
        "\n",
        "        for segment in api_segments:\n",
        "          segment['start'] += last_segment_timestamp\n",
        "          segment['end'] += last_segment_timestamp\n",
        "\n",
        "        ## append new segments\n",
        "        result['segments'].extend(api_segments)\n",
        "\n",
        "        if 'duration' in result:\n",
        "          result['duration'] += api_result.get('duration', 0)\n",
        "      else:\n",
        "        ## first request\n",
        "        result = api_result\n",
        "\n",
        "        if detect_language:\n",
        "          print(f\"Detected language: {result['language'].title()}\\n\")\n",
        "\n",
        "      ## display segments\n",
        "      if options['verbose']:\n",
        "        for segment in api_segments:\n",
        "          print(f\"[{format_timestamp(segment['start'])} --> {format_timestamp(segment['end'])}] {segment['text']}\")\n",
        "  else:\n",
        "    # Open-Source\n",
        "    result = whisper.transcribe(model, audio_path, **options)\n",
        "\n",
        "  # fix results formatting\n",
        "  for segment in result['segments']:\n",
        "    segment['text'] = segment['text'].strip()\n",
        "\n",
        "  result['text'] = '\\n'.join(map(lambda segment: segment['text'], result['segments']))\n",
        "\n",
        "  # set results for this audio file\n",
        "  results[audio_path] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTrxbUivk_h3"
      },
      "source": [
        "## [Step 4] üíæ **Save results**\n",
        "\n",
        "Run this cell to write the transcription as a file output.\n",
        "\n",
        "Results will be available in the **audio_transcription** folder in the formats selected in `output_formats`.\n",
        "\n",
        "If you don't see that folder, you may need to refresh üîÑ the Files folder.\n",
        "\n",
        "Available formats: `txt,vtt,srt,tsv,json`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "wNsrB45_lCIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406e3f63-5753-4fc3-cb02-5090942c7599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing results...\n",
            "\n",
            "audio_transcription/12-10Ë´áËá™Áµê.txt\n"
          ]
        }
      ],
      "source": [
        "# set output folder\n",
        "output_dir = \"audio_transcription\"\n",
        "\n",
        "# set output formats: https://github.com/openai/whisper/blob/v20231117/whisper/utils.py#L283\n",
        "output_formats = \"txt\" #@param [\"txt,vtt,srt,tsv,json\", \"txt,vtt,srt\", \"txt,vtt\", \"txt,srt\", \"txt\", \"vtt\", \"srt\", \"tsv\", \"json\"] {allow-input: true}\n",
        "output_formats = output_formats.split(',')\n",
        "\n",
        "from typing import TextIO\n",
        "\n",
        "class WriteText(WriteTXT):\n",
        "\n",
        "  def write_result(self, result: dict, file: TextIO, **kwargs):\n",
        "    print(result['text'], file=file, flush=True)\n",
        "\n",
        "def write_result(result, output_format, output_file_name):\n",
        "  output_format = output_format.strip()\n",
        "\n",
        "  # start captions in non-zero timestamp (some media players does not detect the first caption)\n",
        "  fix_vtt = output_format == 'vtt' and result['segments'] and result['segments'][0].get('start') == 0\n",
        "\n",
        "  if fix_vtt:\n",
        "    result['segments'][0]['start'] += 1/1000 # +1ms\n",
        "\n",
        "  # write result in the desired format\n",
        "  writer = WriteText(output_dir) if output_format == 'txt' else get_writer(output_format, output_dir)\n",
        "  writer(result, output_file_name)\n",
        "\n",
        "  if fix_vtt:\n",
        "    result['segments'][0]['start'] = 0 # reset change\n",
        "\n",
        "  output_file_path = os.path.join(output_dir, f\"{output_file_name}.{output_format}\")\n",
        "  print(output_file_path)\n",
        "\n",
        "# save results\n",
        "\n",
        "print(\"Writing results...\")\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for audio_path, result in results.items():\n",
        "  print(end='\\n')\n",
        "\n",
        "  output_file_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "\n",
        "  for output_format in output_formats:\n",
        "    write_result(result, output_format, output_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkDhNMMvY8s"
      },
      "source": [
        "## [Step 5] üí¨ Translate results with DeepL (API key needed)\n",
        "\n",
        "This is an **optional** step to translate the transcription to another language using the **DeepL** API.\n",
        "\n",
        "[Get a DeepL Developer Account API Key](https://www.deepl.com/pro-api)\n",
        "\n",
        "Set the `deepl_api_key` to translate the transcription to a supported language in `deepl_target_language`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "28f7EIP-rez0"
      },
      "outputs": [],
      "source": [
        "import deepl\n",
        "\n",
        "# translation service options (DeepL Developer Account)\n",
        "\n",
        "deepl_api_key = \"\" #@param {type:\"string\"}\n",
        "\n",
        "deepl_target_language = \"\" #@param [\"\", \"Bulgarian\", \"Chinese (simplified)\", \"Czech\", \"Danish\", \"Dutch\", \"English (American)\", \"English (British)\", \"Estonian\", \"Finnish\", \"French\", \"German\", \"Greek\", \"Hungarian\", \"Indonesian\", \"Italian\", \"Japanese\", \"Korean\", \"Latvian\", \"Lithuanian\", \"Norwegian\", \"Polish\", \"Portuguese (Brazilian)\", \"Portuguese (European)\", \"Romanian\", \"Russian\", \"Slovak\", \"Slovenian\", \"Spanish\", \"Swedish\", \"Turkish\", \"Ukrainian\"]\n",
        "\n",
        "deepl_formality = \"default\" #@param [\"default\", \"formal\", \"informal\"]\n",
        "\n",
        "deepl_coherence_preference = \"Share context between lines\" #@param [\"Share context between lines\", \"Translate each line independently\"]\n",
        "deepl_coherence_preference = deepl_coherence_preference == \"Share context between lines\"\n",
        "\n",
        "if not deepl_api_key:\n",
        "  print(\"Required: deepl_api_key\")\n",
        "  print(\"Get a DeepL Developer Account API Key: https://www.deepl.com/pro-api\")\n",
        "\n",
        "if not deepl_target_language:\n",
        "  print(\"Required: deepl_target_language\")\n",
        "elif deepl_target_language == 'English':\n",
        "  deepl_target_language = \"English (British)\"\n",
        "elif deepl_target_language == 'Chinese':\n",
        "  deepl_target_language = \"Chinese (simplified)\"\n",
        "elif deepl_target_language == 'Portuguese':\n",
        "  deepl_target_language = \"Portuguese (European)\"\n",
        "\n",
        "use_deepl_translation = deepl_api_key and deepl_target_language\n",
        "\n",
        "if use_deepl_translation:\n",
        "  if deepl_formality != 'default':\n",
        "    deepl_formality = 'prefer_more' if deepl_formality == 'formal' else 'prefer_less'\n",
        "\n",
        "  translated_results = {} # audio_path to translated results\n",
        "\n",
        "  try:\n",
        "    deepl_translator = deepl.Translator(deepl_api_key)\n",
        "\n",
        "    deepl_source_languages = [lang.code.upper() for lang in deepl_translator.get_source_languages()]\n",
        "\n",
        "    deepl_target_languages_dict = deepl_translator.get_target_languages()\n",
        "    deepl_target_languages = [lang.name for lang in deepl_target_languages_dict]\n",
        "\n",
        "    deepl_target_language_code = next(lang.code for lang in deepl_target_languages_dict if lang.name == deepl_target_language).upper()\n",
        "    target_language_code = deepl_target_language_code.split('-')[0]\n",
        "\n",
        "    for audio_path, result in results.items():\n",
        "      deepl_usage = deepl_translator.get_usage()\n",
        "\n",
        "      if deepl_usage.any_limit_reached:\n",
        "        print(audio_path)\n",
        "        raise deepl.DeepLException(\"Quota for this billing period has been exceeded, message: Quota Exceeded\")\n",
        "      else:\n",
        "        print(audio_path + '\\n')\n",
        "\n",
        "      # translate results (DeepL)\n",
        "      source_language_code = whisper.tokenizer.TO_LANGUAGE_CODE.get(result['language'].lower()).upper()\n",
        "\n",
        "      if (task == 'translate' and target_language_code != 'EN') or (task == 'transcribe' and source_language_code in deepl_source_languages and source_language_code != target_language_code):\n",
        "        source_lang = source_language_code if task == 'transcribe' else None\n",
        "        translate_from = f\"from {result['language'].title()} [{source_language_code}] \" if source_lang else ''\n",
        "        print(f\"DeepL: Translate results {translate_from}to {deepl_target_language} [{deepl_target_language_code}]\\n\")\n",
        "\n",
        "        segments = result['segments']\n",
        "\n",
        "        translated_results[audio_path] = { 'text': '', 'segments': [], 'language': deepl_target_language }\n",
        "\n",
        "        # segments / request (max 128 KiB / request, so deepl_batch_requests_size is limited to around 1000)\n",
        "        deepl_batch_requests_size = 200 # 200 segments * ~100 bytes / segment = ~20 KB / request  (~15 minutes of speech)\n",
        "\n",
        "        for batch_segments in [segments[i:i + deepl_batch_requests_size] for i in range(0, len(segments), deepl_batch_requests_size)]:\n",
        "          batch_segments_text = [segment['text'] for segment in batch_segments]\n",
        "\n",
        "          if deepl_coherence_preference:\n",
        "            batch_segments_text = '<br/>'.join(batch_segments_text)\n",
        "\n",
        "          # DeepL request\n",
        "          deepl_results = deepl_translator.translate_text(\n",
        "              text=batch_segments_text,\n",
        "              source_lang=source_lang,\n",
        "              target_lang=deepl_target_language_code,\n",
        "              formality=deepl_formality,\n",
        "              split_sentences='nonewlines',\n",
        "              tag_handling='xml' if deepl_coherence_preference else None,\n",
        "              ignore_tags='br' if deepl_coherence_preference else None, # used to synchronize sentences with whisper lines but without splitting sentences in DeepL\n",
        "              outline_detection=False if deepl_coherence_preference else None\n",
        "          )\n",
        "\n",
        "          deepl_results_segments = deepl_results.text.split('<br/>') if deepl_coherence_preference else [deepl_result_segment.text for deepl_result_segment in deepl_results]\n",
        "\n",
        "          for j, translated_text in enumerate(deepl_results_segments):\n",
        "            segment = batch_segments[j]\n",
        "\n",
        "            # fix sentence formatting\n",
        "            translated_text = translated_text.lstrip(',.„ÄÇ ').rstrip()\n",
        "\n",
        "            if not deepl_coherence_preference and translated_text and translated_text[-1] in '.„ÄÇ' and segment['text'][-1] not in '.„ÄÇ':\n",
        "              translated_text = translated_text[:-1]\n",
        "\n",
        "            # add translated segments\n",
        "            translated_results[audio_path]['segments'].append(dict(id=segment['id'], start=segment['start'], end=segment['end'], text=translated_text))\n",
        "\n",
        "            if options['verbose']:\n",
        "              print(f\"[{format_timestamp(segment['start'])} --> {format_timestamp(segment['end'])}] {translated_text}\")\n",
        "\n",
        "        deepl_usage = deepl_translator.get_usage()\n",
        "\n",
        "        if deepl_usage.character.valid:\n",
        "          print(f\"\\nDeepL: Character usage: {deepl_usage.character.count} / {deepl_usage.character.limit} ({100*(deepl_usage.character.count/deepl_usage.character.limit):.2f}%)\\n\")\n",
        "      elif source_language_code == target_language_code:\n",
        "        print(f\"Nothing to translate. Results are already in {result['language']}.\")\n",
        "      elif task == 'transcribe' and source_language_code not in deepl_source_languages:\n",
        "        print(f\"DeepL: {result['language']} is not yet supported\")\n",
        "  except deepl.DeepLException as e:\n",
        "    if isinstance(e, deepl.AuthorizationException) and str(e) == \"Authorization failure, check auth_key\":\n",
        "      e = \"Authorization failure, check deepl_api_key\"\n",
        "    print(f\"\\nDeepL: [Error] {e}\\n\")\n",
        "\n",
        "  # save translated results (if any)\n",
        "\n",
        "  if translated_results:\n",
        "    print(\"Writing translated results...\")\n",
        "\n",
        "    for audio_path, translated_result in translated_results.items():\n",
        "      print(end='\\n')\n",
        "\n",
        "      translated_result['text'] = '\\n'.join(map(lambda translated_segment: translated_segment['text'], translated_result['segments']))\n",
        "\n",
        "      output_file_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "      translated_output_file_name = f\"{output_file_name}_{deepl_target_language}\"\n",
        "\n",
        "      for output_format in output_formats:\n",
        "        write_result(translated_result, output_format, translated_output_file_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "cf5167ffd3d40c187bbdee173a0e169759f2b54f4182487e61a0f59820dcd535"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}